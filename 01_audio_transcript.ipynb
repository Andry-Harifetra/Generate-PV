{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e9777f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:34:31.402364Z",
     "iopub.status.busy": "2025-09-24T10:34:31.402138Z",
     "iopub.status.idle": "2025-09-24T10:34:31.405882Z",
     "shell.execute_reply": "2025-09-24T10:34:31.405112Z"
    },
    "papermill": {
     "duration": 0.011531,
     "end_time": "2025-09-24T10:34:31.407101",
     "exception": false,
     "start_time": "2025-09-24T10:34:31.395570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# **Installation des packages n√©cessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf30dc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:34:31.417516Z",
     "iopub.status.busy": "2025-09-24T10:34:31.417023Z",
     "iopub.status.idle": "2025-09-24T10:37:45.372245Z",
     "shell.execute_reply": "2025-09-24T10:37:45.371145Z"
    },
    "papermill": {
     "duration": 193.962071,
     "end_time": "2025-09-24T10:37:45.374125",
     "exception": false,
     "start_time": "2025-09-24T10:34:31.412054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Installation silencieuse des d√©pendances avec gestion des conflits\n",
    "\n",
    "# 1. Mise √† jour pip pour √©viter les probl√®mes\n",
    "!pip install --upgrade pip -q\n",
    "\n",
    "# 2. Installation FFmpeg (syst√®me)\n",
    "!apt-get update -qq\n",
    "!apt-get install -qq ffmpeg\n",
    "\n",
    "# 3. Installation des packages de transcription\n",
    "!pip install -q openai-whisper==20250625\n",
    "!pip install -q faster-whisper==1.2.0\n",
    "\n",
    "# 4. Packages de d√©bruitage audio\n",
    "!pip install -q librosa==0.10.1\n",
    "!pip install -q soundfile==0.12.1\n",
    "!pip install -q noisereduce==3.0.0\n",
    "!pip install -q scipy==1.11.4\n",
    "!pip install -q pydub==0.25.1\n",
    "\n",
    "# 5. Packages documents\n",
    "!pip install -q python-docx==1.2.0\n",
    "!pip install -q python-pptx==1.0.2\n",
    "\n",
    "# 6. Packages LLM et NLP\n",
    "!pip install -q openai==1.91.0\n",
    "!pip install -q assemblyai==0.44.3\n",
    "!pip install -q tiktoken==0.9.0\n",
    "\n",
    "# 7. LangChain\n",
    "!pip install -q langchain==0.3.27 langchain-community==0.3.29 langchain-core -q 2>/dev/null || true\n",
    "\n",
    "# 8. Packages utilitaires\n",
    "!pip install -q numpy==1.24.3\n",
    "!pip install -q pandas matplotlib seaborn\n",
    "\n",
    "# 9. Installation FAISS pour le RAG\n",
    "!pip install -q faiss-cpu==1.12.0\n",
    "\n",
    "print(\"‚úÖ Installation termin√©e!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efbf73a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:37:45.385410Z",
     "iopub.status.busy": "2025-09-24T10:37:45.385162Z",
     "iopub.status.idle": "2025-09-24T10:38:00.597793Z",
     "shell.execute_reply": "2025-09-24T10:38:00.596797Z"
    },
    "papermill": {
     "duration": 15.21988,
     "end_time": "2025-09-24T10:38:00.599258",
     "exception": false,
     "start_time": "2025-09-24T10:37:45.379378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç V√©rification des packages install√©s:\n",
      "--------------------------------------------------\n",
      "‚úÖ openai-whisper       : 20250625\n",
      "‚úÖ faster-whisper       : 1.2.0\n",
      "‚úÖ librosa              : 0.10.1\n",
      "‚úÖ soundfile            : 0.12.1\n",
      "‚úÖ noisereduce          : N/A\n",
      "‚úÖ scipy                : 1.11.4\n",
      "‚úÖ pydub                : N/A\n",
      "‚úÖ python-docx          : 1.2.0\n",
      "‚úÖ python-pptx          : 1.0.2\n",
      "‚úÖ openai               : 1.91.0\n",
      "‚úÖ langchain            : 0.3.27\n",
      "‚úÖ langchain-community  : 0.3.29\n",
      "‚úÖ faiss-cpu            : 1.12.0\n",
      "‚úÖ assemblyai           : 0.44.3\n",
      "‚úÖ tiktoken             : 0.9.0\n",
      "\n",
      "‚ú® Tous les packages sont install√©s correctement!\n"
     ]
    }
   ],
   "source": [
    "# V√©rification que tout est install√© correctement\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "packages_to_check = [\n",
    "    ('whisper', 'openai-whisper'),\n",
    "    ('faster_whisper', 'faster-whisper'),\n",
    "    ('librosa', 'librosa'),\n",
    "    ('soundfile', 'soundfile'),\n",
    "    ('noisereduce', 'noisereduce'),\n",
    "    ('scipy', 'scipy'),\n",
    "    ('pydub', 'pydub'),\n",
    "    ('docx', 'python-docx'),\n",
    "    ('pptx', 'python-pptx'),\n",
    "    ('openai', 'openai'),\n",
    "    ('langchain', 'langchain'),\n",
    "    ('langchain_community', 'langchain-community'),\n",
    "    ('faiss', 'faiss-cpu'),\n",
    "    ('assemblyai', 'assemblyai'),\n",
    "    ('tiktoken', 'tiktoken')\n",
    "]\n",
    "\n",
    "print(\"üîç V√©rification des packages install√©s:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_ok = True\n",
    "for import_name, package_name in packages_to_check:\n",
    "    try:\n",
    "        module = importlib.import_module(import_name)\n",
    "        version = getattr(module, '__version__', 'N/A')\n",
    "        print(f\"‚úÖ {package_name:20} : {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package_name:20} : Non install√©\")\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\n‚ú® Tous les packages sont install√©s correctement!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Certains packages manquent. Relancez la cellule 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5887a",
   "metadata": {
    "papermill": {
     "duration": 0.004801,
     "end_time": "2025-09-24T10:38:00.609583",
     "exception": false,
     "start_time": "2025-09-24T10:38:00.604782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Imports et configuration GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f12c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:00.621470Z",
     "iopub.status.busy": "2025-09-24T10:38:00.621142Z",
     "iopub.status.idle": "2025-09-24T10:38:01.138216Z",
     "shell.execute_reply": "2025-09-24T10:38:01.137259Z"
    },
    "papermill": {
     "duration": 0.525249,
     "end_time": "2025-09-24T10:38:01.139552",
     "exception": false,
     "start_time": "2025-09-24T10:38:00.614303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß PyTorch: 2.6.0+cu124\n",
      "üéÆ CUDA disponible: True\n",
      "   GPU: Tesla T4\n",
      "   M√©moire: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "# Imports standards\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "import re\n",
    "import subprocess\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "except Exception:\n",
    "    ZoneInfo = None\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import gc  # Garbage collector\n",
    "\n",
    "# Imports audio et d√©bruitage\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "from scipy.signal import butter, filtfilt, medfilt\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Imports pour la transcription\n",
    "import whisper\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# Imports pour les documents\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "\n",
    "# Imports pour le NLP et LLM\n",
    "import openai\n",
    "try:\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain_community.embeddings import OpenAIEmbeddings\n",
    "    langchain_available = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è LangChain non disponible\")\n",
    "    langchain_available = False\n",
    "\n",
    "import torch\n",
    "print(f\"üîß PyTorch: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   M√©moire: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdca5db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.151884Z",
     "iopub.status.busy": "2025-09-24T10:38:01.151480Z",
     "iopub.status.idle": "2025-09-24T10:38:01.338849Z",
     "shell.execute_reply": "2025-09-24T10:38:01.338222Z"
    },
    "papermill": {
     "duration": 0.195305,
     "end_time": "2025-09-24T10:38:01.340124",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.144819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration des cl√©s API\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "OPENAI_API_KEY = user_secrets.get_secret(\"OPENAI_API_KEY\")\n",
    "ASSEMBLYAI_API_KEY = user_secrets.get_secret(\"ASSEMBLYAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0037028d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.351489Z",
     "iopub.status.busy": "2025-09-24T10:38:01.351273Z",
     "iopub.status.idle": "2025-09-24T10:38:01.354603Z",
     "shell.execute_reply": "2025-09-24T10:38:01.354002Z"
    },
    "papermill": {
     "duration": 0.010388,
     "end_time": "2025-09-24T10:38:01.355898",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.345510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration des chemins \n",
    "UPLOAD_PATH = \"/kaggle/input/meeting-audio/\" # Chemin des fichiers upload√©s \n",
    "OUTPUT_PATH = \"/kaggle/working\" # Chemin de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18b789d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.366949Z",
     "iopub.status.busy": "2025-09-24T10:38:01.366679Z",
     "iopub.status.idle": "2025-09-24T10:38:01.379557Z",
     "shell.execute_reply": "2025-09-24T10:38:01.378713Z"
    },
    "papermill": {
     "duration": 0.019641,
     "end_time": "2025-09-24T10:38:01.380558",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.360917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e - Mod√®le Whisper: large-v3\n"
     ]
    }
   ],
   "source": [
    "# Configuration du pipeline \n",
    "@dataclass \n",
    "class Config: \n",
    "    \"\"\"Configuration centralis√©e pour Kaggle\"\"\" \n",
    "\n",
    "    # Chemins\n",
    "    input_dir: str = UPLOAD_PATH\n",
    "    output_dir: str = OUTPUT_PATH\n",
    "    \n",
    "    timezone: str = \"Indian/Antananarivo\"\n",
    "    \n",
    "    # Mod√®le Whisper \n",
    "    whisper_model: str = \"large-v3\" # 'tiny', 'base', 'small', 'medium', 'large'\n",
    "    whisper_device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    whisper_compute_type: str = \"float16\" if torch.cuda.is_available() else \"int8\"\n",
    "    #device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    compute_type: str = \"float16\" if torch.cuda.is_available() else \"int8\"\n",
    "    \n",
    "    openai_model: str = \"gpt-3.5-turbo\" # Plus √©conomique que GPT-4 \n",
    "    \n",
    "    # Cl√©s API \n",
    "    openai_key: str = OPENAI_API_KEY \n",
    "    assemblyai_key: str = ASSEMBLYAI_API_KEY\n",
    "\n",
    "    # Param√®tres audio\n",
    "    denoise_method: str = \"hybrid\"  # ffmpeg, noisereduce, hybrid\n",
    "    denoise_aggressive: bool = True\n",
    "    sample_rate: int = 16000\n",
    "\n",
    "    # Param√®tres de traitement \n",
    "    \n",
    "    ## Longueur maximale d‚Äôun ‚Äúmorceau de texte‚Äù (chunk) qu‚Äôon d√©coupe avant d‚Äôenvoyer au LLM.\n",
    "    ## R√®gle : chunk_size ‚âà 20-30% de la capacit√© max du mod√®le.\n",
    "    chunk_size: int = 1000 # nombre de caract√®re ‚âà 200‚Äì250 tokens (selon la langue et la densit√©) √† modifier selon la limitation du mod√®le choisie (ex. GPT-3.5 ‚âà 4k tokens, GPT-4 ‚âà 8k ou 32k).\n",
    "    \n",
    "    ## Nombre de caract√®res r√©p√©t√©s entre deux chunks.\n",
    "    ## R√®gle : overlap = 15-25% du chunk_size.\n",
    "    chunk_overlap: int = 200 # nombre de caract√®re ‚âà 40 tokens. Suffisant pour garder la continuit√© (phrases coup√©es, dialogues, etc.).\n",
    "    \n",
    "    ## Proportion maximale de mots que le LLM a le droit de modifier dans une transcription brute.\n",
    "    ## R√®gle : plus l‚Äôaudio est bruit√©, plus tu tol√®res une correction √©lev√©e. [propre (dictaphone, micro-cravate) ‚Üí mettre bas (0.10 √† 0.15). / bruyant (claquements de porte, plusieurs intervenants) ‚Üí monter √† 0.20 voire 0.25]\n",
    "    max_correction_rate: float = 0.15 # Max 15% du texte peut √™tre modifi√© (Pas de r√©√©criture compl√®te ‚Üí garde la fid√©lit√© au discours original.) Evite les hallucinations\n",
    "    \n",
    "    ## Score minimal de confiance (0‚Äì1) pour garder une phrase transcrite par Whisper/AssemblyAI.\n",
    "    confidence_threshold: float = 0.85 #Segments dont la transcription est jug√©e correcte √† au moins 85%.\n",
    "\n",
    "    # Optimisation m√©moire pour Kaggle \n",
    "    num_workers: int = 2  # Ajust√© pour T4\n",
    "    batch_size: int = 4 # Pour le traitement par lots [Si CPU seulement ‚Üí descendre (1‚Äì2).]\n",
    "    use_gpu: bool = torch.cuda.is_available()\n",
    "\n",
    "    # NOUVEAUX PARAM√àTRES ANTI-HALLUCINATIONS\n",
    "    beam_size: int = 3  # Plus de beam = plus de pr√©cision\n",
    "    best_of: int = 2    # Prendre le meilleur de 3 tentatives\n",
    "    patience: float = 1.0\n",
    "    temperature: float = 0.0  # Pas de randomness\n",
    "    \n",
    "    # Seuils de confiance stricts\n",
    "    no_speech_threshold: float = 0.8 # Plus strict\n",
    "    logprob_threshold: float = -0.5  # Plus strict\n",
    "    compression_ratio_threshold: float = 2.8  # √âvite les r√©p√©titions\n",
    "\n",
    "    # NOUVEAU: Param√®tres anti-r√©p√©tition\n",
    "    max_initial_timestamp: float = 1.0\n",
    "    suppress_blank: bool = True\n",
    "    suppress_tokens: str = \"-1\"  # Supprime les tokens probl√©matiques\n",
    "    \n",
    "    # VAD (Voice Activity Detection) optimis√©\n",
    "    use_vad: bool = True\n",
    "    vad_threshold: float = 0.45\n",
    "    vad_min_speech_duration_ms: int = 500  # Minimum 250ms de parole\n",
    "    vad_max_speech_duration_s: float = 60  # Max 30s par segment\n",
    "    vad_min_silence_duration_ms: int = 1000  # 2s de silence minimum\n",
    "    vad_speech_pad_ms: int = 400\n",
    "\n",
    "    # NOUVEAU: Chunking intelligent\n",
    "    chunk_length_s: int = 300  # Chunks de 5 minutes max\n",
    "    chunk_overlap_s: int = 30   # Overlap de 30 secondes\n",
    "    \n",
    "    # Audio processing\n",
    "    sample_rate: int = 16000\n",
    "    use_denoise: bool = \"auto\"  # auto, True, False\n",
    "    denoise_stationary: float = 0.97\n",
    "    denoise_prop_decrease: float = 1.0\n",
    "    \n",
    "    # D√©tection r√©p√©titions\n",
    "    repetition_penalty: float = 1.2  # NOUVEAU\n",
    "    max_repetitions: int = 3  # NOUVEAU: max r√©p√©titions tol√©r√©es\n",
    "    \n",
    "    # Prompt sp√©cialis√© CA - AM√âLIOR√â\n",
    "    # PROMPT AM√âLIOR√â avec contexte financier malgache\n",
    "    initial_prompt: str = (\n",
    "        \"Conseil d'administration Madagascar. Vocabulaire financier: Ariary, millions, \"\n",
    "        \"budget, rapport financier, r√©solution, d√©lib√©ration. \"\n",
    "        \"Termes sp√©cifiques: Fihariana, SON'INVEST, UNIMA, AQUALMA. \"\n",
    "        \"Intervenants: Pr√©sident, Directeur G√©n√©ral, Commissaire aux Comptes. \"\n",
    "        \"Format: discours naturel sans r√©p√©titions.\"\n",
    "    )\n",
    "\n",
    "config = Config() \n",
    "print(f\"‚úÖ Configuration charg√©e - Mod√®le Whisper: {config.whisper_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9022bdb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.391698Z",
     "iopub.status.busy": "2025-09-24T10:38:01.391480Z",
     "iopub.status.idle": "2025-09-24T10:38:01.397284Z",
     "shell.execute_reply": "2025-09-24T10:38:01.396461Z"
    },
    "papermill": {
     "duration": 0.012816,
     "end_time": "2025-09-24T10:38:01.398573",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.385757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_audio_file(audio_path: str) -> Dict:\n",
    "    \"\"\"Pr√©pare et valide le fichier audio pour la transcription\"\"\"\n",
    "    import wave\n",
    "    import contextlib\n",
    "    \n",
    "    file_info = {\n",
    "        \"path\": audio_path,\n",
    "        \"exists\": os.path.exists(audio_path),\n",
    "        \"size_mb\": 0,\n",
    "        \"duration_seconds\": 0,\n",
    "        \"format\": audio_path.split('.')[-1],\n",
    "        \"sample_rate\": 0,\n",
    "        \"channels\": 0\n",
    "    }\n",
    "    \n",
    "    if file_info[\"exists\"]:\n",
    "        file_info[\"size_mb\"] = os.path.getsize(audio_path) / (1024 * 1024)\n",
    "        \n",
    "        try:\n",
    "            # Charger avec librosa pour info\n",
    "            y, sr = librosa.load(audio_path, sr=None, duration=10)\n",
    "            file_info[\"sample_rate\"] = sr\n",
    "            \n",
    "            # Dur√©e totale\n",
    "            duration = librosa.get_duration(path=audio_path)\n",
    "            file_info[\"duration_seconds\"] = duration\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erreur lecture audio: {e}\")\n",
    "    \n",
    "    return file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3dabd05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.410011Z",
     "iopub.status.busy": "2025-09-24T10:38:01.409509Z",
     "iopub.status.idle": "2025-09-24T10:38:01.413940Z",
     "shell.execute_reply": "2025-09-24T10:38:01.413102Z"
    },
    "papermill": {
     "duration": 0.011407,
     "end_time": "2025-09-24T10:38:01.415214",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.403807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Convertit des secondes en format HH:MM:SS\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:02d}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020ee3b",
   "metadata": {
    "papermill": {
     "duration": 0.00495,
     "end_time": "2025-09-24T10:38:01.425086",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.420136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Pr√©processing et D√©bruitage Audio**\n",
    "**Classe de d√©bruitage audio avanc√©**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdede981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.435774Z",
     "iopub.status.busy": "2025-09-24T10:38:01.435527Z",
     "iopub.status.idle": "2025-09-24T10:38:01.443440Z",
     "shell.execute_reply": "2025-09-24T10:38:01.442785Z"
    },
    "papermill": {
     "duration": 0.014541,
     "end_time": "2025-09-24T10:38:01.444597",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.430056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioPreprocessor:\n",
    "    \"\"\"Service de pr√©traitement audio avec d√©tection intelligente du bruit\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "    \n",
    "    def analyze_noise_profile(self, audio_path: str, duration: int = 30) -> Dict:\n",
    "        \"\"\"Analyse le profil de bruit de l'audio\"\"\"\n",
    "        print(\"üîç Analyse du niveau de bruit...\")\n",
    "        \n",
    "        y, sr = librosa.load(audio_path, sr=self.config.sample_rate, duration=duration)\n",
    "        \n",
    "        # Calculer le SNR\n",
    "        signal_power = np.mean(y ** 2)\n",
    "        noise_floor = np.percentile(np.abs(y), 5) ** 2\n",
    "        snr = 10 * np.log10(signal_power / (noise_floor + 1e-10))\n",
    "        \n",
    "        # D√©tecter les silences\n",
    "        silence_threshold = np.percentile(np.abs(y), 20)\n",
    "        silence_ratio = np.sum(np.abs(y) < silence_threshold) / len(y)\n",
    "        \n",
    "        # D√©tecter les impulsions (clics, pops)\n",
    "        impulses = np.sum(np.abs(np.diff(y)) > 0.5) / len(y)\n",
    "        \n",
    "        return {\n",
    "            \"snr\": float(snr),\n",
    "            \"silence_ratio\": float(silence_ratio),\n",
    "            \"impulse_ratio\": float(impulses),\n",
    "            \"needs_denoising\": bool(snr < 20 or impulses > 0.001)\n",
    "        }\n",
    "    \n",
    "    def apply_denoising(self, audio_path: str, output_path: str = None) -> str:\n",
    "        \"\"\"Applique un d√©bruitage intelligent\"\"\"\n",
    "        print(\"üîß Application du d√©bruitage adaptatif...\")\n",
    "        \n",
    "        if output_path is None:\n",
    "            output_path = audio_path.replace(\".mp3\", \"_denoised.wav\")\n",
    "        \n",
    "        # Charger l'audio complet\n",
    "        y, sr = librosa.load(audio_path, sr=self.config.sample_rate)\n",
    "        \n",
    "        # D√©bruitage stationnaire\n",
    "        y_denoised = nr.reduce_noise(\n",
    "            y=y,\n",
    "            sr=sr,\n",
    "            stationary=True,\n",
    "            prop_decrease=self.config.denoise_prop_decrease\n",
    "        )\n",
    "        \n",
    "        # Normalisation douce\n",
    "        max_val = np.max(np.abs(y_denoised))\n",
    "        if max_val > 0:\n",
    "            y_denoised = y_denoised * (0.95 / max_val)\n",
    "        \n",
    "        # Sauvegarder\n",
    "        sf.write(output_path, y_denoised, sr)\n",
    "        print(f\"‚úÖ Audio d√©bruit√© sauvegard√©: {output_path}\")\n",
    "        \n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb091d",
   "metadata": {
    "papermill": {
     "duration": 0.004705,
     "end_time": "2025-09-24T10:38:01.454433",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.449728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Transcription Audio**\n",
    "**Service de transcription avec audio nettoy√©**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e95014c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.465603Z",
     "iopub.status.busy": "2025-09-24T10:38:01.465394Z",
     "iopub.status.idle": "2025-09-24T10:38:01.489497Z",
     "shell.execute_reply": "2025-09-24T10:38:01.488700Z"
    },
    "papermill": {
     "duration": 0.031245,
     "end_time": "2025-09-24T10:38:01.490678",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.459433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranscriptionService:\n",
    "    \"\"\"Service de transcription Whisper avec d√©tection et correction des r√©p√©titions\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.preprocessor = AudioPreprocessor(config)\n",
    "        self.repetition_buffer = []  # Buffer pour d√©tecter les r√©p√©titions\n",
    "        \n",
    "    def load_whisper_model(self):\n",
    "        \"\"\"Charge le mod√®le Whisper avec gestion m√©moire optimis√©e\"\"\"\n",
    "        if self.model is None:\n",
    "            print(f\"‚è≥ Chargement Whisper {self.config.whisper_model}...\")\n",
    "            \n",
    "            # Lib√©rer la m√©moire GPU\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "            \n",
    "            # Charger avec faster-whisper (plus efficace)\n",
    "            self.model = WhisperModel(\n",
    "                self.config.whisper_model,\n",
    "                device=self.config.whisper_device,\n",
    "                compute_type=self.config.whisper_compute_type,\n",
    "                cpu_threads=8 if self.config.whisper_device == \"cpu\" else 0,\n",
    "                num_workers=2  # R√©duit pour √©viter les probl√®mes\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Mod√®le charg√© sur\", self.config.whisper_device.upper())\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def detect_repetitions(self, text: str, window_size: int = 100) -> bool:\n",
    "        \"\"\"D√©tecte les r√©p√©titions dans le texte\"\"\"\n",
    "        words = text.lower().split()\n",
    "        \n",
    "        if len(words) < window_size:\n",
    "            return False\n",
    "        \n",
    "        # V√©rifier les r√©p√©titions dans une fen√™tre glissante\n",
    "        for i in range(len(words) - window_size):\n",
    "            window = words[i:i + window_size]\n",
    "            unique_ratio = len(set(window)) / len(window)\n",
    "            \n",
    "            # Si moins de 30% de mots uniques, c'est une r√©p√©tition\n",
    "            if unique_ratio < 0.3:\n",
    "                return True\n",
    "        \n",
    "        # V√©rifier les r√©p√©titions exactes de phrases\n",
    "        sentences = text.split('.')\n",
    "        if len(sentences) > 3:\n",
    "            last_3 = sentences[-3:]\n",
    "            if len(set(last_3)) == 1 and len(last_3[0]) > 10:\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def clean_repetitions(self, segments: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Nettoie les segments r√©p√©titifs\"\"\"\n",
    "        cleaned = []\n",
    "        repetition_count = {}\n",
    "        \n",
    "        for segment in segments:\n",
    "            text = segment['text'].strip()\n",
    "            \n",
    "            # Compter les occurrences\n",
    "            if text in repetition_count:\n",
    "                repetition_count[text] += 1\n",
    "                \n",
    "                # Si trop de r√©p√©titions, ignorer\n",
    "                if repetition_count[text] > self.config.max_repetitions:\n",
    "                    continue\n",
    "            else:\n",
    "                repetition_count[text] = 1\n",
    "            \n",
    "            # D√©tecter les r√©p√©titions partielles\n",
    "            if len(cleaned) > 0:\n",
    "                last_text = cleaned[-1]['text']\n",
    "                \n",
    "                # Si le texte est identique ou tr√®s similaire au pr√©c√©dent\n",
    "                if text == last_text or (len(text) > 20 and text in last_text):\n",
    "                    continue\n",
    "            \n",
    "            cleaned.append(segment)\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def transcribe_chunk(self, audio_chunk: np.ndarray, sr: int, offset: float = 0) -> List[Dict]:\n",
    "        \"\"\"Transcrit un chunk audio avec gestion des r√©p√©titions\"\"\"\n",
    "        \n",
    "        # Sauvegarder temporairement le chunk\n",
    "        temp_file = f\"/tmp/chunk_{offset}.wav\"\n",
    "        sf.write(temp_file, audio_chunk, sr)\n",
    "        \n",
    "        try:\n",
    "            # Transcrire avec param√®tres optimis√©s\n",
    "            segments, info = self.model.transcribe(\n",
    "                temp_file,\n",
    "                language=\"fr\",\n",
    "                beam_size=self.config.beam_size,\n",
    "                best_of=self.config.best_of,\n",
    "                patience=self.config.patience,\n",
    "                temperature=self.config.temperature,\n",
    "                compression_ratio_threshold=self.config.compression_ratio_threshold,\n",
    "                log_prob_threshold=self.config.logprob_threshold,\n",
    "                no_speech_threshold=self.config.no_speech_threshold,\n",
    "                condition_on_previous_text=False,  # IMPORTANT: D√©sactiv√© pour √©viter propagation\n",
    "                initial_prompt=self.config.initial_prompt,\n",
    "                vad_filter=self.config.use_vad,\n",
    "                vad_parameters={\n",
    "                    \"threshold\": self.config.vad_threshold,\n",
    "                    \"min_speech_duration_ms\": self.config.vad_min_speech_duration_ms,\n",
    "                    \"min_silence_duration_ms\": self.config.vad_min_silence_duration_ms,\n",
    "                    \"speech_pad_ms\": self.config.vad_speech_pad_ms,\n",
    "                    \"max_speech_duration_s\": self.config.vad_max_speech_duration_s\n",
    "                },\n",
    "                word_timestamps=True,\n",
    "                suppress_blank=self.config.suppress_blank,\n",
    "                max_initial_timestamp=self.config.max_initial_timestamp\n",
    "            )\n",
    "            \n",
    "            # Convertir en liste et ajuster les timestamps\n",
    "            segment_list = []\n",
    "            for seg in segments:\n",
    "                segment_dict = {\n",
    "                    'id': len(segment_list),\n",
    "                    'start': float(seg.start + offset),\n",
    "                    'end': float(seg.end + offset),\n",
    "                    'text': seg.text,\n",
    "                    'confidence': float(getattr(seg, 'confidence', 0)),\n",
    "                    'no_speech_prob': float(seg.no_speech_prob) if hasattr(seg, 'no_speech_prob') else 0.0\n",
    "                }\n",
    "                \n",
    "                # Filtrer les segments de faible qualit√©\n",
    "                if segment_dict['confidence'] < -1.0 or segment_dict['no_speech_prob'] > 0.9:\n",
    "                    continue\n",
    "                \n",
    "                segment_list.append(segment_dict)\n",
    "            \n",
    "            return segment_list\n",
    "            \n",
    "        finally:\n",
    "            # Nettoyer le fichier temporaire\n",
    "            if os.path.exists(temp_file):\n",
    "                os.remove(temp_file)\n",
    "    \n",
    "    def transcribe_with_chunking(self, audio_path: str) -> Dict:\n",
    "        \"\"\"Transcription avec chunking intelligent pour √©viter les d√©rives\"\"\"\n",
    "        print(\"üéØ Transcription avec chunking intelligent...\")\n",
    "        \n",
    "        # Charger l'audio\n",
    "        y, sr = librosa.load(audio_path, sr=self.config.sample_rate)\n",
    "        duration = len(y) / sr\n",
    "        \n",
    "        # Calculer les chunks\n",
    "        chunk_samples = int(self.config.chunk_length_s * sr)\n",
    "        overlap_samples = int(self.config.chunk_overlap_s * sr)\n",
    "        \n",
    "        all_segments = []\n",
    "        \n",
    "        # Traiter par chunks\n",
    "        num_chunks = max(1, int(np.ceil((len(y) - overlap_samples) / (chunk_samples - overlap_samples))))\n",
    "        \n",
    "        for i in range(num_chunks):\n",
    "            start_sample = i * (chunk_samples - overlap_samples)\n",
    "            end_sample = min(start_sample + chunk_samples, len(y))\n",
    "            \n",
    "            chunk = y[start_sample:end_sample]\n",
    "            offset = start_sample / sr\n",
    "            \n",
    "            print(f\"  Chunk {i+1}/{num_chunks}: {format_timestamp(offset)} - {format_timestamp(end_sample/sr)}\")\n",
    "            \n",
    "            # Transcrire le chunk\n",
    "            chunk_segments = self.transcribe_chunk(chunk, sr, offset)\n",
    "            \n",
    "            # D√©tecter et nettoyer les r√©p√©titions\n",
    "            chunk_segments = self.clean_repetitions(chunk_segments)\n",
    "            \n",
    "            # Fusionner avec les segments pr√©c√©dents\n",
    "            if i > 0 and len(all_segments) > 0:\n",
    "                # G√©rer l'overlap - garder seulement les nouveaux segments apr√®s l'overlap\n",
    "                overlap_time = offset + self.config.chunk_overlap_s / 2\n",
    "                chunk_segments = [s for s in chunk_segments if s['start'] > overlap_time]\n",
    "            \n",
    "            all_segments.extend(chunk_segments)\n",
    "            \n",
    "            # V√©rification anti-d√©rive\n",
    "            if len(all_segments) > 10:\n",
    "                recent_texts = [s['text'] for s in all_segments[-10:]]\n",
    "                if len(set(recent_texts)) == 1:\n",
    "                    print(\"‚ö†Ô∏è R√©p√©tition d√©tect√©e - r√©initialisation du contexte\")\n",
    "                    # R√©initialiser pour le prochain chunk\n",
    "                    self.config.initial_prompt = \"Transcription suite. Nouveau contexte.\"\n",
    "        \n",
    "        # Nettoyer une derni√®re fois l'ensemble\n",
    "        all_segments = self.clean_repetitions(all_segments)\n",
    "        \n",
    "        # Construire la transcription finale\n",
    "        transcription = \" \".join([s['text'] for s in all_segments])\n",
    "        \n",
    "        return {\n",
    "            \"transcription\": transcription,\n",
    "            \"segments\": all_segments,\n",
    "            \"duration\": float(duration),\n",
    "            \"language\": \"fr\"\n",
    "        }\n",
    "    \n",
    "    def transcribe_with_preprocessing(self, audio_path: str, preprocess: bool = None, language: str = \"fr\") -> Dict:\n",
    "        \"\"\"Pipeline complet avec pr√©traitement optionnel\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"üéØ TRANSCRIPTION AVEC PR√âPROCESSING INTELLIGENT\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        result = {\n",
    "            \"status\": \"processing\",\n",
    "            \"original_audio\": audio_path,\n",
    "            \"preprocessing_applied\": preprocess\n",
    "        }\n",
    "        \n",
    "        # √âtape 1: Analyse du bruit si auto\n",
    "        if preprocess == \"auto\" or preprocess is None:\n",
    "            noise_profile = self.preprocessor.analyze_noise_profile(audio_path)\n",
    "            preprocess = noise_profile[\"needs_denoising\"]\n",
    "            result[\"noise_profile\"] = noise_profile\n",
    "            \n",
    "            print(f\"  SNR: {noise_profile['snr']:.1f} dB\")\n",
    "            print(f\"  Silence: {noise_profile['silence_ratio']*100:.1f}%\")\n",
    "            print(f\"  Impulsions: {noise_profile['impulse_ratio']*1000:.2f}/1000 samples\")\n",
    "            \n",
    "            if preprocess:\n",
    "                print(\"  ‚Üí D√©bruitage recommand√©\")\n",
    "            else:\n",
    "                print(\"  ‚Üí Audio propre, pas de d√©bruitage n√©cessaire\")\n",
    "        \n",
    "        # √âtape 2: Pr√©processing si n√©cessaire\n",
    "        if preprocess:\n",
    "            print(\"\\nüîß Application du d√©bruitage...\")\n",
    "            audio_to_transcribe = self.preprocessor.apply_denoising(audio_path)\n",
    "        else:\n",
    "            audio_to_transcribe = audio_path\n",
    "        \n",
    "        # √âtape 3: Transcription avec chunking\n",
    "        print(f\"\\nüìù Transcription de l'audio {'nettoy√©' if preprocess else 'original'}...\")\n",
    "        \n",
    "        try:\n",
    "            # Charger le mod√®le\n",
    "            self.load_whisper_model()\n",
    "            \n",
    "            # Transcrire avec chunking intelligent\n",
    "            transcription_result = self.transcribe_with_chunking(audio_to_transcribe)\n",
    "            \n",
    "            # Calculer la confiance moyenne\n",
    "            if transcription_result[\"segments\"]:\n",
    "                avg_confidence = np.mean([s.get('confidence', 0) for s in transcription_result[\"segments\"]])\n",
    "            else:\n",
    "                avg_confidence = 0\n",
    "            \n",
    "            result.update({\n",
    "                \"status\": \"success\",\n",
    "                \"transcription\": transcription_result[\"transcription\"],\n",
    "                \"segments\": transcription_result[\"segments\"],\n",
    "                \"duration\": transcription_result[\"duration\"],\n",
    "                \"language\": transcription_result[\"language\"],\n",
    "                \"confidence\": avg_confidence\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n‚úÖ Transcription r√©ussie!\")\n",
    "            print(f\"  üìä Confiance moyenne: {avg_confidence:.2%}\")\n",
    "            print(f\"  üìù Longueur: {len(result['transcription'])} caract√®res\")\n",
    "            print(f\"  ‚è±Ô∏è Dur√©e audio: {result['duration']:.1f}s\")\n",
    "            print(f\"  üìë Segments: {len(result['segments'])}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur transcription: {e}\")\n",
    "            result[\"status\"] = \"error\"\n",
    "            result[\"error\"] = str(e)\n",
    "        \n",
    "        finally:\n",
    "            # Nettoyer les fichiers temporaires\n",
    "            if preprocess and audio_to_transcribe != audio_path:\n",
    "                if os.path.exists(audio_to_transcribe):\n",
    "                    os.remove(audio_to_transcribe)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e85d2",
   "metadata": {
    "papermill": {
     "duration": 0.004833,
     "end_time": "2025-09-24T10:38:01.500467",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.495634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Comment r√©gler les param√®tres selon les cas***\n",
    "\n",
    "Cas A ‚Äî Audio propre (dictaphones, salle calme)\n",
    "*  beam_size=3, best_of=1‚Äì2 (plus rapide)\n",
    "* no_speech_threshold=0.6 (ok)\n",
    "* temperature=0.0\n",
    "* VAD : min_silence_duration_ms=1500\n",
    "\n",
    "Cas B ‚Äî Audio bruit√© (portes, brouhaha)\n",
    "* beam_size=5, best_of=5 (qualit√©)\n",
    "* baisser no_speech_threshold √† 0.5 si coupures\n",
    "* VAD : threshold=0.4‚Äì0.5, min_speech_duration_ms=200, min_silence_duration_ms=1800‚Äì2200\n",
    "* Garde-fous : garder compression_ratio_threshold=2.4\n",
    "\n",
    "Cas C ‚Äî CPU-only (pas de GPU Kaggle)\n",
    "* compute_type=\"int8\", mod√®le tiny ou base\n",
    "* beam_size=3, best_of=1\n",
    "* Threads : cpu_threads=2, num_workers=1\n",
    "* Attends un RTF ‚âà 2‚Äì5 (selon longueur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb98d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.510925Z",
     "iopub.status.busy": "2025-09-24T10:38:01.510675Z",
     "iopub.status.idle": "2025-09-24T10:38:01.513875Z",
     "shell.execute_reply": "2025-09-24T10:38:01.513090Z"
    },
    "papermill": {
     "duration": 0.009852,
     "end_time": "2025-09-24T10:38:01.515116",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.505264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "#result = transcription_service.transcribe_audio(audio_file)\n",
    "#print(f\"Transcription: {result['transcription'][:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09267b5e",
   "metadata": {
    "papermill": {
     "duration": 0.004859,
     "end_time": "2025-09-24T10:38:01.524892",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.520033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Service d'analyse de qualit√©**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9132192b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.535483Z",
     "iopub.status.busy": "2025-09-24T10:38:01.535271Z",
     "iopub.status.idle": "2025-09-24T10:38:01.544006Z",
     "shell.execute_reply": "2025-09-24T10:38:01.543334Z"
    },
    "papermill": {
     "duration": 0.015455,
     "end_time": "2025-09-24T10:38:01.545135",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.529680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QualityAnalyzer:\n",
    "    \"\"\"Analyse la qualit√© de la transcription et d√©tecte les probl√®mes\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "    \n",
    "    def analyze_transcription(self, result: Dict) -> Dict:\n",
    "        \"\"\"Analyse compl√®te de la qualit√©\"\"\"\n",
    "        \n",
    "        if result[\"status\"] != \"success\":\n",
    "            return {\"status\": \"error\", \"message\": \"Transcription √©chou√©e\"}\n",
    "        \n",
    "        text = result[\"transcription\"]\n",
    "        segments = result[\"segments\"]\n",
    "        \n",
    "        analysis = {\n",
    "            \"total_length\": len(text),\n",
    "            \"total_segments\": len(segments),\n",
    "            \"repetitions\": {},\n",
    "            \"quality_issues\": [],\n",
    "            \"statistics\": {}\n",
    "        }\n",
    "        \n",
    "        # D√©tecter les r√©p√©titions\n",
    "        words = text.lower().split()\n",
    "        word_freq = {}\n",
    "        for word in words:\n",
    "            if len(word) > 3:  # Ignorer les mots courts\n",
    "                word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        \n",
    "        # Identifier les mots trop fr√©quents\n",
    "        total_words = len(words)\n",
    "        for word, count in word_freq.items():\n",
    "            ratio = count / total_words\n",
    "            if ratio > 0.05:  # Plus de 5% du texte\n",
    "                analysis[\"repetitions\"][word] = {\n",
    "                    \"count\": count,\n",
    "                    \"ratio\": ratio\n",
    "                }\n",
    "                if ratio > 0.1:\n",
    "                    analysis[\"quality_issues\"].append(f\"Mot '{word}' r√©p√©t√© {count} fois ({ratio:.1%})\")\n",
    "        \n",
    "        # Analyser les segments\n",
    "        low_confidence = sum(1 for s in segments if s.get('confidence', 0) < -0.5)\n",
    "        high_no_speech = sum(1 for s in segments if s.get('no_speech_prob', 0) > 0.6)\n",
    "        \n",
    "        avg_conf = float(np.mean([s.get('confidence', 0) for s in segments])) if segments else 0.0\n",
    "        \n",
    "        analysis[\"statistics\"] = {\n",
    "            \"avg_confidence\": avg_conf,\n",
    "            \"low_confidence_segments\": low_confidence,\n",
    "            \"high_no_speech_segments\": high_no_speech,\n",
    "            \"words_per_segment\": float(total_words / len(segments)) if segments else 0.0\n",
    "        }\n",
    "        \n",
    "        # Identifier les probl√®mes\n",
    "        if low_confidence > len(segments) * 0.3:\n",
    "            analysis[\"quality_issues\"].append(f\"{low_confidence} segments avec faible confiance\")\n",
    "        \n",
    "        if high_no_speech > len(segments) * 0.2:\n",
    "            analysis[\"quality_issues\"].append(f\"{high_no_speech} segments d√©tect√©s comme silence\")\n",
    "        \n",
    "        # Score de qualit√© global\n",
    "        quality_score = 100\n",
    "        quality_score -= len(analysis[\"repetitions\"]) * 5\n",
    "        quality_score -= len(analysis[\"quality_issues\"]) * 10\n",
    "        quality_score = max(0, quality_score)\n",
    "        \n",
    "        analysis[\"quality_score\"] = quality_score\n",
    "        \n",
    "        return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a29b34",
   "metadata": {
    "papermill": {
     "duration": 0.004742,
     "end_time": "2025-09-24T10:38:01.554882",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.550140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Fallback AssemblyAI (si √©chec Whisper)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3150af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.565488Z",
     "iopub.status.busy": "2025-09-24T10:38:01.565242Z",
     "iopub.status.idle": "2025-09-24T10:38:01.572193Z",
     "shell.execute_reply": "2025-09-24T10:38:01.571656Z"
    },
    "papermill": {
     "duration": 0.013445,
     "end_time": "2025-09-24T10:38:01.573142",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.559697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AssemblyAIFallback:\n",
    "    \"\"\"Service de fallback avec AssemblyAI\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        \n",
    "    def transcribe_with_assemblyai(self, audio_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Transcription de secours via AssemblyAI\n",
    "        \n",
    "        Args:\n",
    "            audio_path: Chemin du fichier audio\n",
    "            \n",
    "        Returns:\n",
    "            Dict avec la transcription\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"Cl√© API AssemblyAI non configur√©e\"\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            import assemblyai as aai\n",
    "            \n",
    "            print(\"üîÑ Utilisation du fallback AssemblyAI...\")\n",
    "            \n",
    "            aai.settings.api_key = self.api_key\n",
    "            transcriber = aai.Transcriber()\n",
    "            \n",
    "            # Upload et transcription\n",
    "            config_lang = aai.TranscriptionConfig(\n",
    "                language_code=\"fr\",\n",
    "                punctuate=True,\n",
    "                format_text=True,\n",
    "                disfluencies=True,\n",
    "                speaker_labels=True\n",
    "            )\n",
    "            transcript = transcriber.transcribe(audio_path, config=config_lang)\n",
    "            \n",
    "            if transcript.status == aai.TranscriptStatus.error:\n",
    "                raise Exception(f\"Erreur AssemblyAI: {transcript.error}\")\n",
    "            \n",
    "            # Attente de la transcription\n",
    "            while transcript.status not in [aai.TranscriptStatus.completed, aai.TranscriptStatus.error]:\n",
    "                time.sleep(5)\n",
    "                transcript = transcriber.get_transcript(transcript.id)\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"method\": \"assemblyai\",\n",
    "                \"transcription\": transcript.text,\n",
    "                \"confidence\": transcript.confidence if hasattr(transcript, 'confidence') else 0.85,\n",
    "                \"words\": transcript.words if hasattr(transcript, 'words') else []\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur AssemblyAI: {str(e)}\")\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"method\": \"assemblyai\"\n",
    "            }\n",
    "\n",
    "# Service de fallback\n",
    "fallback_service = AssemblyAIFallback(config.assemblyai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f72c7d",
   "metadata": {
    "papermill": {
     "duration": 0.004769,
     "end_time": "2025-09-24T10:38:01.582780",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.578011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Par d√©faut, la langue est auto. Pour ton cas, force fran√ßais :\n",
    "        config = aai.TranscriptionConfig(language_code=\"fr\")\n",
    "2. Diarisation (orateurs)\n",
    "        config = aai.TranscriptionConfig(speaker_labels=True)\n",
    "\n",
    "Exemple :\n",
    "    config = aai.TranscriptionConfig(language_code=\"fr\", speaker_labels=True)\n",
    "    transcript = transcriber.transcribe(audio_path, config=config)\n",
    "\n",
    "Appel :\n",
    "    Si TranscriptionService.transcribe_audio renvoie status=\"error\" ou un real_time_factor >> 5 (trop lent) ou trop de segments sous ton confidence_threshold, alors :\n",
    "        > result = fallback_service.transcribe_with_assemblyai(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cb6fe",
   "metadata": {
    "papermill": {
     "duration": 0.00471,
     "end_time": "2025-09-24T10:38:01.592477",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.587767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Pipeline de transcription avec gestion automatique du fallback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06c700a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.603146Z",
     "iopub.status.busy": "2025-09-24T10:38:01.602907Z",
     "iopub.status.idle": "2025-09-24T10:38:01.614126Z",
     "shell.execute_reply": "2025-09-24T10:38:01.613561Z"
    },
    "papermill": {
     "duration": 0.017849,
     "end_time": "2025-09-24T10:38:01.615238",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.597389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transcribe_audio_pipeline(\n",
    "    audio_path: str, \n",
    "    config: Config,\n",
    "    force_denoise: Optional[bool] = None,\n",
    "    analyze_quality: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Pipeline complet de transcription avec analyse de qualit√©\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Chemin du fichier audio\n",
    "        config: Configuration\n",
    "        force_denoise: Forcer le d√©bruitage (None=auto)\n",
    "        analyze_quality: Analyser la qualit√© apr√®s transcription\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"üéØ PIPELINE DE TRANSCRIPTION INTELLIGENT V2\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Pr√©parer le fichier\n",
    "    file_info = prepare_audio_file(audio_path)\n",
    "    print(f\"üìÅ Fichier: {os.path.basename(audio_path)}\")\n",
    "    print(f\"   Format: {file_info['format']}\")\n",
    "    print(f\"   Dur√©e: {format_timestamp(file_info['duration_seconds'])}\")\n",
    "    print(f\"   Taille: {file_info['size_mb']:.1f} MB\")\n",
    "    \n",
    "    # Service de transcription\n",
    "    transcription_service = TranscriptionService(config)\n",
    "    \n",
    "    # D√©terminer si d√©bruitage n√©cessaire\n",
    "    if force_denoise is None:\n",
    "        force_denoise = \"auto\"\n",
    "    \n",
    "    # Transcription\n",
    "    result = transcription_service.transcribe_with_preprocessing(\n",
    "        audio_path,\n",
    "        preprocess=force_denoise,\n",
    "        language=\"fr\"\n",
    "    )\n",
    "    \n",
    "    # Analyse de qualit√©\n",
    "    if analyze_quality and result[\"status\"] == \"success\":\n",
    "        print(\"\\nüìä Analyse de la qualit√©...\")\n",
    "        analyzer = QualityAnalyzer(config)\n",
    "        quality = analyzer.analyze_transcription(result)\n",
    "        result[\"quality_analysis\"] = quality\n",
    "        \n",
    "        print(f\"   Score de qualit√©: {quality['quality_score']}/100\")\n",
    "        \n",
    "        if quality[\"quality_issues\"]:\n",
    "            print(\"   ‚ö†Ô∏è Probl√®mes d√©tect√©s:\")\n",
    "            for issue in quality[\"quality_issues\"]:\n",
    "                print(f\"      - {issue}\")\n",
    "        \n",
    "        if quality[\"repetitions\"]:\n",
    "            print(\"   üîÑ R√©p√©titions excessives:\")\n",
    "            for word, data in list(quality[\"repetitions\"].items())[:3]:\n",
    "                print(f\"      - '{word}': {data['count']} fois ({data['ratio']:.1%})\")\n",
    "    \n",
    "    # Sauvegarder le r√©sultat\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = f\"{config.output_dir}/transcription_{timestamp}.json\"\n",
    "    \n",
    "    # Convertir les types NumPy en types Python natifs pour JSON\n",
    "    def convert_numpy_types(obj):\n",
    "        \"\"\"Convertit r√©cursivement les types NumPy en types Python natifs\"\"\"\n",
    "        import numpy as np\n",
    "        \n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, (np.bool_, bool)):\n",
    "            return bool(obj)\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_numpy_types(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    # Nettoyer le r√©sultat avant sauvegarde\n",
    "    result_clean = convert_numpy_types(result)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result_clean, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ R√©sultat sauvegard√©: {output_file}\")\n",
    "    \n",
    "    # R√©sum√© final\n",
    "    if result[\"status\"] == \"success\":\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"‚úÖ TRANSCRIPTION R√âUSSIE\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"üìù M√©thode: Whisper {config.whisper_model}\")\n",
    "        print(f\"üìä Confiance: {result.get('confidence', 0):.2%}\")\n",
    "        print(f\"üìë Segments: {len(result.get('segments', []))}\")\n",
    "        print(f\"üìÑ Longueur: {len(result.get('transcription', ''))} caract√®res\")\n",
    "        \n",
    "        if analyze_quality:\n",
    "            print(f\"‚≠ê Qualit√©: {result['quality_analysis']['quality_score']}/100\")\n",
    "        \n",
    "        # Aper√ßu\n",
    "        text = result.get('transcription', '')\n",
    "        if text:\n",
    "            print(f\"\\nüìñ Aper√ßu (300 premiers caract√®res):\")\n",
    "            print(f\"   {text[:300]}...\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå √âchec transcription: {result.get('error')}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2c1abe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.625839Z",
     "iopub.status.busy": "2025-09-24T10:38:01.625569Z",
     "iopub.status.idle": "2025-09-24T10:38:01.628875Z",
     "shell.execute_reply": "2025-09-24T10:38:01.628299Z"
    },
    "papermill": {
     "duration": 0.010071,
     "end_time": "2025-09-24T10:38:01.630032",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.619961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test avec votre fichier audio\n",
    "#audio_file = f\"{UPLOAD_PATH}atelier.mp3\"\n",
    "#audio_file = f\"{UPLOAD_PATH}test_1h.wav\"\n",
    "audio_file = f\"{UPLOAD_PATH}test_30mn.mp3\"\n",
    "#audio_info = prepare_audio_file(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e4b297d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.640390Z",
     "iopub.status.busy": "2025-09-24T10:38:01.640154Z",
     "iopub.status.idle": "2025-09-24T10:38:01.643261Z",
     "shell.execute_reply": "2025-09-24T10:38:01.642634Z"
    },
    "papermill": {
     "duration": 0.009526,
     "end_time": "2025-09-24T10:38:01.644334",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.634808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transcription_result = transcribe_audio_pipeline(\n",
    "#             audio_file, \n",
    "#             config,\n",
    "#             force_denoise=None  # Auto-d√©tection\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2485ab49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T10:38:01.654709Z",
     "iopub.status.busy": "2025-09-24T10:38:01.654494Z",
     "iopub.status.idle": "2025-09-24T10:40:56.010871Z",
     "shell.execute_reply": "2025-09-24T10:40:56.009708Z"
    },
    "papermill": {
     "duration": 174.363003,
     "end_time": "2025-09-24T10:40:56.012209",
     "exception": false,
     "start_time": "2025-09-24T10:38:01.649206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier trouv√©: /kaggle/input/meeting-audio/test_30mn.mp3\n",
      "======================================================================\n",
      "üéØ PIPELINE DE TRANSCRIPTION INTELLIGENT V2\n",
      "======================================================================\n",
      "üìÅ Fichier: test_30mn.mp3\n",
      "   Format: mp3\n",
      "   Dur√©e: 00:32:08\n",
      "   Taille: 73.5 MB\n",
      "============================================================\n",
      "üéØ TRANSCRIPTION AVEC PR√âPROCESSING INTELLIGENT\n",
      "============================================================\n",
      "üîç Analyse du niveau de bruit...\n",
      "  SNR: 41.1 dB\n",
      "  Silence: 20.0%\n",
      "  Impulsions: 0.00/1000 samples\n",
      "  ‚Üí Audio propre, pas de d√©bruitage n√©cessaire\n",
      "\n",
      "üìù Transcription de l'audio original...\n",
      "‚è≥ Chargement Whisper large-v3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0357fcdbec94815aa897d5d2316ce52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c409c6853cde413e918fa8a5b1cc0152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30ad1a766de4b7a9f528ace03a3db65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1904ebae69094b61a0cf44d8bf5cc9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46aefab104834f55b247eaba624d97b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le charg√© sur CUDA\n",
      "üéØ Transcription avec chunking intelligent...\n",
      "  Chunk 1/8: 00:00:00 - 00:05:00\n",
      "  Chunk 2/8: 00:04:30 - 00:09:30\n",
      "  Chunk 3/8: 00:09:00 - 00:14:00\n",
      "  Chunk 4/8: 00:13:30 - 00:18:30\n",
      "  Chunk 5/8: 00:18:00 - 00:23:00\n",
      "  Chunk 6/8: 00:22:30 - 00:27:30\n",
      "  Chunk 7/8: 00:27:00 - 00:32:00\n",
      "  Chunk 8/8: 00:31:30 - 00:32:08\n",
      "\n",
      "‚úÖ Transcription r√©ussie!\n",
      "  üìä Confiance moyenne: 0.00%\n",
      "  üìù Longueur: 15870 caract√®res\n",
      "  ‚è±Ô∏è Dur√©e audio: 1928.0s\n",
      "  üìë Segments: 232\n",
      "\n",
      "üìä Analyse de la qualit√©...\n",
      "   Score de qualit√©: 90/100\n",
      "   ‚ö†Ô∏è Probl√®mes d√©tect√©s:\n",
      "      - 71 segments d√©tect√©s comme silence\n",
      "\n",
      "üíæ R√©sultat sauvegard√©: /kaggle/working/transcription_20250924_104055.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ TRANSCRIPTION R√âUSSIE\n",
      "======================================================================\n",
      "üìù M√©thode: Whisper large-v3\n",
      "üìä Confiance: 0.00%\n",
      "üìë Segments: 232\n",
      "üìÑ Longueur: 15870 caract√®res\n",
      "‚≠ê Qualit√©: 90/100\n",
      "\n",
      "üìñ Aper√ßu (300 premiers caract√®res):\n",
      "    R√©alisation des documents n√©cessaires √† ce Conseil  ...  Merci.  Et la hausse du taux de base bancaire √† 12%, ceci nous donne un peu plus de r√©sultats √† fin juin 2025 et aussi √† l'estimation au 31 d√©cembre 2025.  Donc dans le tableau qui est pr√©sent√©, il y a dans le budget 2025, les co√ªts d'exploit...\n",
      "\n",
      "üìà STATISTIQUES FINALES:\n",
      "----------------------------------------\n",
      "Score qualit√©: 90/100\n",
      "R√©p√©titions d√©tect√©es: 0\n",
      "Probl√®mes identifi√©s: 1\n",
      "Confiance moyenne: 0.000\n",
      "Mots/segment: 11.7\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier l'existence du fichier\n",
    "if os.path.exists(audio_file):\n",
    "    print(f\"‚úÖ Fichier trouv√©: {audio_file}\")\n",
    "    \n",
    "    # Lancer la transcription avec le pipeline am√©lior√©\n",
    "    transcription_result = transcribe_audio_pipeline(\n",
    "        audio_file, \n",
    "        config,\n",
    "        force_denoise=None,  # Auto-d√©tection\n",
    "        analyze_quality=True  # Analyse de qualit√© activ√©e\n",
    "    )\n",
    "    \n",
    "    # Afficher les statistiques finales\n",
    "    if transcription_result[\"status\"] == \"success\":\n",
    "        print(\"\\nüìà STATISTIQUES FINALES:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if \"quality_analysis\" in transcription_result:\n",
    "            qa = transcription_result[\"quality_analysis\"]\n",
    "            print(f\"Score qualit√©: {qa['quality_score']}/100\")\n",
    "            print(f\"R√©p√©titions d√©tect√©es: {len(qa['repetitions'])}\")\n",
    "            print(f\"Probl√®mes identifi√©s: {len(qa['quality_issues'])}\")\n",
    "            \n",
    "            if qa['statistics']:\n",
    "                print(f\"Confiance moyenne: {qa['statistics']['avg_confidence']:.3f}\")\n",
    "                print(f\"Mots/segment: {qa['statistics']['words_per_segment']:.1f}\")\n",
    "else:\n",
    "    print(f\"‚ùå Fichier non trouv√©: {audio_file}\")\n",
    "    print(\"Veuillez ajuster le chemin du fichier audio dans la cellule ci-dessus.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8302666,
     "sourceId": 13136823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 393.123243,
   "end_time": "2025-09-24T10:40:58.850576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-24T10:34:25.727333",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ab0232920d243c9ac053b48927aa438": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc870ee183714753977ab99a3be2c4c3",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7f1d25541ef345fb88c6f165fd70c190",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá2.48M/?‚Äá[00:00&lt;00:00,‚Äá8.89MB/s]"
      }
     },
     "0f786121fe0240df804ffb96265405d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1424bc7274e14fe380f054900a0c7191": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "15086a6b28ff4d5a9856e9072330f162": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "178de525fcbb443185bc177c4ab5f814": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "189c0fde413b46bc9ab81259a40fae2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1904ebae69094b61a0cf44d8bf5cc9ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_813296fb9dda46e38515390006d2de49",
        "IPY_MODEL_52bb471df6b7400db165b63978598183",
        "IPY_MODEL_f9c68995ec6d434aba245cf44519f105"
       ],
       "layout": "IPY_MODEL_0f786121fe0240df804ffb96265405d5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2215b1ad187a47acb6696e3bc4d65672": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "24bf9c5d346d47ea94c8ebe5668500cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2a45bb626c8d46bbb98ac54fc6336ada": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2db77e65f00a498282df80d549134bae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_41312cf754ba43cabfc81fcae811496e",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ddbadbc2562d4ceb9048856ef355318b",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá3.09G/3.09G‚Äá[00:15&lt;00:00,‚Äá128MB/s]"
      }
     },
     "2ffbe9e4e8e14fbe8ba015a9c4591e76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3512082e4a3d45708456134c79294969": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35eda94a9d2e4db9adbeb5c70f7bc134": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4dc1dbc2aa304c3bb70940e28c1def5d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_b37db294ab5146a7a74bfdc5a980f58a",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:‚Äá"
      }
     },
     "3680e9c52f0948acbdebce502bf9991c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3512082e4a3d45708456134c79294969",
       "max": 3087284237.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_edae73c6afef40e5af9f564161f8e2d8",
       "tabbable": null,
       "tooltip": null,
       "value": 3087284237.0
      }
     },
     "3ce4a222e9ea4e69bc165981f3a3c559": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9e10a73bbcb54cafb64f087a2631395a",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ca0c37ca75c74b7889fad7f8fe9f539f",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:‚Äá"
      }
     },
     "41312cf754ba43cabfc81fcae811496e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4425f84966594b90bfe6ba64e5074eb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "46aefab104834f55b247eaba624d97b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_86d9bc75b1d54a0bb647bf0e24613008",
        "IPY_MODEL_3680e9c52f0948acbdebce502bf9991c",
        "IPY_MODEL_2db77e65f00a498282df80d549134bae"
       ],
       "layout": "IPY_MODEL_fcebc0b3391346efaec9de08f1c70f7d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4dc1dbc2aa304c3bb70940e28c1def5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4eec20b6cb7d47d485a64d42f606eed1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4425f84966594b90bfe6ba64e5074eb9",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_24bf9c5d346d47ea94c8ebe5668500cc",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "52bb471df6b7400db165b63978598183": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81c4a72f06dd4b1d98e64241ab67fecc",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fd3bd8e11f13436889ca677918f55b69",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "561417df70c24567be6364f6e5b704d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca70605e94634a5dae1956d0df8f2708",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_15086a6b28ff4d5a9856e9072330f162",
       "tabbable": null,
       "tooltip": null,
       "value": "preprocessor_config.json:‚Äá100%"
      }
     },
     "71a3772a4cf84eaa80bdad4a927585d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a6102e94a8974848afa39e4eadaf66a2",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f074701c23ec444f95cfb124164460f7",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "71d58bca0e9f4b299b46a293aa8df3d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "763cbbcf5ff04100a9a3431943b8b34a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_920c113f98ea45ceab87e86259e8a22d",
       "max": 340.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eb0a1693958a49f6b9f04d1baec9c89d",
       "tabbable": null,
       "tooltip": null,
       "value": 340.0
      }
     },
     "7f1d25541ef345fb88c6f165fd70c190": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "813296fb9dda46e38515390006d2de49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ffbe9e4e8e14fbe8ba015a9c4591e76",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ea9a22dc87ba416d8b7a5b408981edde",
       "tabbable": null,
       "tooltip": null,
       "value": "vocabulary.json:‚Äá"
      }
     },
     "81c4a72f06dd4b1d98e64241ab67fecc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "86d9bc75b1d54a0bb647bf0e24613008": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a45bb626c8d46bbb98ac54fc6336ada",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_178de525fcbb443185bc177c4ab5f814",
       "tabbable": null,
       "tooltip": null,
       "value": "model.bin:‚Äá100%"
      }
     },
     "920c113f98ea45ceab87e86259e8a22d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c7455615b214cf38aec4f5ffb864b51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e10a73bbcb54cafb64f087a2631395a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0357fcdbec94815aa897d5d2316ce52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_561417df70c24567be6364f6e5b704d1",
        "IPY_MODEL_763cbbcf5ff04100a9a3431943b8b34a",
        "IPY_MODEL_f3f442966d5740a68a05c49c5bbe3c88"
       ],
       "layout": "IPY_MODEL_2215b1ad187a47acb6696e3bc4d65672",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a30ad1a766de4b7a9f528ace03a3db65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_35eda94a9d2e4db9adbeb5c70f7bc134",
        "IPY_MODEL_4eec20b6cb7d47d485a64d42f606eed1",
        "IPY_MODEL_f01528655454465188bdd4bedcdc57b7"
       ],
       "layout": "IPY_MODEL_189c0fde413b46bc9ab81259a40fae2f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a6102e94a8974848afa39e4eadaf66a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "b37db294ab5146a7a74bfdc5a980f58a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bc870ee183714753977ab99a3be2c4c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bef3200caa854ac594eb759dd657e231": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c409c6853cde413e918fa8a5b1cc0152": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3ce4a222e9ea4e69bc165981f3a3c559",
        "IPY_MODEL_71a3772a4cf84eaa80bdad4a927585d2",
        "IPY_MODEL_0ab0232920d243c9ac053b48927aa438"
       ],
       "layout": "IPY_MODEL_c4fd7f44385243bbb1a850f302d7d8da",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c43983c08f9346c2a6030935afb1b135": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c4fd7f44385243bbb1a850f302d7d8da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ca0c37ca75c74b7889fad7f8fe9f539f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ca70605e94634a5dae1956d0df8f2708": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d211650efea446e49f6feaf2ccbaed94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddbadbc2562d4ceb9048856ef355318b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ea9a22dc87ba416d8b7a5b408981edde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eb0a1693958a49f6b9f04d1baec9c89d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "edae73c6afef40e5af9f564161f8e2d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f01528655454465188bdd4bedcdc57b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9c7455615b214cf38aec4f5ffb864b51",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_c43983c08f9346c2a6030935afb1b135",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá2.39k/?‚Äá[00:00&lt;00:00,‚Äá155kB/s]"
      }
     },
     "f074701c23ec444f95cfb124164460f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f3f442966d5740a68a05c49c5bbe3c88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d211650efea446e49f6feaf2ccbaed94",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_71d58bca0e9f4b299b46a293aa8df3d9",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá340/340‚Äá[00:00&lt;00:00,‚Äá21.6kB/s]"
      }
     },
     "f9c68995ec6d434aba245cf44519f105": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bef3200caa854ac594eb759dd657e231",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_1424bc7274e14fe380f054900a0c7191",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.07M/?‚Äá[00:00&lt;00:00,‚Äá28.3MB/s]"
      }
     },
     "fcebc0b3391346efaec9de08f1c70f7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd3bd8e11f13436889ca677918f55b69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
