{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fd6532",
   "metadata": {
    "papermill": {
     "duration": 0.007652,
     "end_time": "2025-09-29T08:40:24.623359",
     "exception": false,
     "start_time": "2025-09-29T08:40:24.615707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transcription CA\n",
    "\n",
    "Ce notebook applique le **pipeline complet** :\n",
    "- **Prétraitement** audio (FFmpeg + noisereduce)\n",
    "- **Transcription** faster-whisper (réglages anti-hallucinations)\n",
    "- **Chunks longs** pour une meilleure cohérence (3–5 min)\n",
    "- **Diarisation** (pyannote → fallback whisperx)\n",
    "- **Post-traitement** (dédup + normalisation chiffres/unités)\n",
    "- **Nettoyage LLM** par morceaux (1000 caractères) avec borne de correction\n",
    "- **Sauvegarde JSON** des sorties (raw, diarized, cleaned, llm_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3cd91",
   "metadata": {
    "papermill": {
     "duration": 0.00709,
     "end_time": "2025-09-29T08:40:24.637048",
     "exception": false,
     "start_time": "2025-09-29T08:40:24.629958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Installation des packages nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0046e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:24.650913Z",
     "iopub.status.busy": "2025-09-29T08:40:24.650669Z",
     "iopub.status.idle": "2025-09-29T08:40:24.657430Z",
     "shell.execute_reply": "2025-09-29T08:40:24.656715Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015055,
     "end_time": "2025-09-29T08:40:24.658595",
     "exception": false,
     "start_time": "2025-09-29T08:40:24.643540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# # Installation silencieuse des dépendances avec gestion des conflits\n",
    "\n",
    "# # 1. Mise à jour pip pour éviter les problèmes\n",
    "# #!pip install --upgrade pip -q\n",
    "\n",
    "# # 2. Installation FFmpeg (système)\n",
    "# !apt-get update -qq\n",
    "# !apt-get install -qq ffmpeg sox\n",
    "\n",
    "# # 3. Nettoyage et verrouillage de la stack NumPy/Numba/Scipy\n",
    "# #!pip uninstall -y numpy numba >/dev/null 2>&1 || true\n",
    "# !pip install -q numpy==1.26.4 scipy==1.11.4\n",
    "# !pip install -q numba==0.58.1\n",
    "# !pip install -q torch==2.1.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# # 4. Installation des packages de transcription\n",
    "# #!pip install -q openai-whisper==20231117\n",
    "# !pip install -q faster-whisper==1.0.3\n",
    "\n",
    "# # 5. Packages de débruitage audio\n",
    "# !pip install -q librosa==0.10.1\n",
    "# !pip install -q soundfile==0.12.1\n",
    "# !pip install -q noisereduce==3.0.0\n",
    "# !pip install -q pydub==0.25.1\n",
    "\n",
    "# # 6. Diarization\n",
    "# !pip install -q \"pyannote.audio>=3.1\"\n",
    "# !pip install -q whisperx\n",
    "\n",
    "# !pip install -q regex==2023.12.25 unidecode==1.3.8\n",
    "\n",
    "# # 7. Packages documents\n",
    "# !pip install -q python-docx==1.2.0\n",
    "# !pip install -q python-pptx==1.0.2\n",
    "\n",
    "# # 8. Packages LLM et NLP\n",
    "# !pip install -q openai==1.91.0\n",
    "# !pip install -q assemblyai==0.44.3\n",
    "# !pip install -q tiktoken==0.9.0\n",
    "\n",
    "# # 9. LangChain\n",
    "# #!pip install -q langchain==0.3.27 langchain-community==0.3.29 langchain-core==0.3.30\n",
    "\n",
    "# # 10. Packages utilitaires\n",
    "# !pip install -q pandas==2.1.4 matplotlib==3.8.2 seaborn==0.13.2\n",
    "\n",
    "# # 11. Installation FAISS pour le RAG\n",
    "# #!pip install -q faiss-cpu==1.7.4\n",
    "\n",
    "# print(\"✅ Installation terminée!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e99d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:24.672406Z",
     "iopub.status.busy": "2025-09-29T08:40:24.672212Z",
     "iopub.status.idle": "2025-09-29T08:40:36.972210Z",
     "shell.execute_reply": "2025-09-29T08:40:36.971607Z"
    },
    "papermill": {
     "duration": 12.30827,
     "end_time": "2025-09-29T08:40:36.973597",
     "exception": false,
     "start_time": "2025-09-29T08:40:24.665327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 36.9 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 253.0/253.0 kB 277.9 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 472.8/472.8 kB 300.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 kB 281.8 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.4/34.4 MB 331.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.6/38.6 MB 334.3 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 329.1 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 175.3/175.3 kB 311.7 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 278.6 MB/s eta 0:00:00\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 296.3 MB/s eta 0:00:00\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# Installation minimale des dépendances nécessaires sans perturber l'environnement Kaggle\n",
    "import importlib\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def ensure_packages(requirements):\n",
    "    missing = []\n",
    "    for module_name, package_spec in requirements:\n",
    "        try:\n",
    "            importlib.import_module(module_name)\n",
    "        except Exception:\n",
    "            missing.append(package_spec)\n",
    "    if missing:\n",
    "        cmd = [sys.executable, '-m', 'pip', 'install', '--no-cache-dir', '-q'] + missing\n",
    "        subprocess.check_call(cmd)\n",
    "\n",
    "core_requirements = [\n",
    "    ('faster_whisper', 'faster-whisper==1.0.3'),\n",
    "    ('librosa', 'librosa==0.10.1'),\n",
    "    ('soundfile', 'soundfile==0.12.1'),\n",
    "    ('noisereduce', 'noisereduce==3.0.0'),\n",
    "    ('pydub', 'pydub==0.25.1'),\n",
    "    ('docx', 'python-docx==1.2.0'),\n",
    "    ('pptx', 'python-pptx==1.0.2'),\n",
    "    ('openai', 'openai==1.91.0'),\n",
    "    ('assemblyai', 'assemblyai==0.44.3'),\n",
    "    ('tiktoken', 'tiktoken==0.9.0'),\n",
    "]\n",
    "\n",
    "ensure_packages(core_requirements)\n",
    "\n",
    "# if os.environ.get('INSTALL_LANGCHAIN', '0') == '1':\n",
    "#     optional_requirements = [\n",
    "#         ('langchain', 'langchain==0.3.27'),\n",
    "#         ('langchain_community', 'langchain-community==0.3.29'),\n",
    "#         ('faiss', 'faiss-cpu==1.7.4'),\n",
    "#     ]\n",
    "#     try:\n",
    "#         ensure_packages(optional_requirements)\n",
    "#     except subprocess.CalledProcessError:\n",
    "#         pass\n",
    "\n",
    "if not shutil.which('ffmpeg'):\n",
    "    subprocess.check_call(['apt-get', 'update', '-qq'])\n",
    "    subprocess.check_call(['apt-get', 'install', '-qq', 'ffmpeg'])\n",
    "\n",
    "print('✅ Vérification des dépendances terminée')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3915e50a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:36.988377Z",
     "iopub.status.busy": "2025-09-29T08:40:36.987777Z",
     "iopub.status.idle": "2025-09-29T08:40:54.185548Z",
     "shell.execute_reply": "2025-09-29T08:40:54.184715Z"
    },
    "papermill": {
     "duration": 17.206024,
     "end_time": "2025-09-29T08:40:54.186685",
     "exception": false,
     "start_time": "2025-09-29T08:40:36.980661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Vérification des packages installés:\n",
      "--------------------------------------------------\n",
      "✅ numpy                : 1.26.4\n",
      "✅ scipy                : 1.15.3\n",
      "✅ numba                : 0.60.0\n",
      "❌ openai-whisper       : Non installé\n",
      "✅ faster-whisper       : 1.0.3\n",
      "✅ librosa              : 0.11.0\n",
      "✅ soundfile            : 0.13.1\n",
      "✅ noisereduce          : N/A\n",
      "✅ pydub                : N/A\n",
      "✅ python-docx          : 1.2.0\n",
      "✅ python-pptx          : 1.0.2\n",
      "✅ openai               : 1.91.0\n",
      "✅ langchain            : 0.3.26\n",
      "❌ langchain-community  : Non installé\n",
      "❌ faiss-cpu            : Non installé\n",
      "✅ assemblyai           : 0.44.3\n",
      "✅ tiktoken             : 0.9.0\n",
      "⚠️ Certains packages nécessitent une attention. Consultez les messages ci-dessus.\n"
     ]
    }
   ],
   "source": [
    "# Vérification que tout est installé correctement\n",
    "import importlib\n",
    "\n",
    "packages_to_check = [\n",
    "    ('numpy', 'numpy'),\n",
    "    ('scipy', 'scipy'),\n",
    "    ('numba', 'numba'),\n",
    "    ('whisper', 'openai-whisper'),\n",
    "    ('faster_whisper', 'faster-whisper'),\n",
    "    ('librosa', 'librosa'),\n",
    "    ('soundfile', 'soundfile'),\n",
    "    ('noisereduce', 'noisereduce'),\n",
    "    ('pydub', 'pydub'),\n",
    "    ('docx', 'python-docx'),\n",
    "    ('pptx', 'python-pptx'),\n",
    "    ('openai', 'openai'),\n",
    "    ('langchain', 'langchain'),\n",
    "    ('langchain_community', 'langchain-community'),\n",
    "    ('faiss', 'faiss-cpu'),\n",
    "    ('assemblyai', 'assemblyai'),\n",
    "    ('tiktoken', 'tiktoken')\n",
    "]\n",
    "\n",
    "print(\"🔍 Vérification des packages installés:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_ok = True\n",
    "for import_name, package_name in packages_to_check:\n",
    "    try:\n",
    "        module = importlib.import_module(import_name)\n",
    "        version = getattr(module, '__version__', 'N/A')\n",
    "        print(f\"✅ {package_name:20} : {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {package_name:20} : Non installé\")\n",
    "        all_ok = False\n",
    "    except Exception as exc:\n",
    "        print(f\"⚠️ {package_name:20} : Erreur lors de l'import ({type(exc).__name__}: {exc})\")\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"✨ Tous les packages sont installés correctement!\")\n",
    "else:\n",
    "    print(\"⚠️ Certains packages nécessitent une attention. Consultez les messages ci-dessus.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af6b249",
   "metadata": {
    "papermill": {
     "duration": 0.00628,
     "end_time": "2025-09-29T08:40:54.199949",
     "exception": false,
     "start_time": "2025-09-29T08:40:54.193669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Imports et configuration GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b02a068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:54.213696Z",
     "iopub.status.busy": "2025-09-29T08:40:54.213339Z",
     "iopub.status.idle": "2025-09-29T08:40:56.206461Z",
     "shell.execute_reply": "2025-09-29T08:40:56.205521Z"
    },
    "papermill": {
     "duration": 2.001548,
     "end_time": "2025-09-29T08:40:56.207825",
     "exception": false,
     "start_time": "2025-09-29T08:40:54.206277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ LangChain non disponible\n",
      "🔧 PyTorch: 2.6.0+cu124\n",
      "🎮 CUDA disponible: True\n",
      "   GPU: Tesla T4\n",
      "   Mémoire: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "# Imports standards\n",
    "import os, sys, json, re, shutil, subprocess, tempfile\n",
    "from math import ceil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "import gc  # Garbage collector\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Imports audio et débruitage\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "from scipy.signal import butter, filtfilt, medfilt\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Imports pour la transcription\n",
    "#import whisper\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# Imports pour les documents\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "\n",
    "# Imports pour le NLP et LLM\n",
    "import openai\n",
    "try:\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain_community.embeddings import OpenAIEmbeddings\n",
    "    langchain_available = True\n",
    "except ImportError:\n",
    "    print(\"⚠️ LangChain non disponible\")\n",
    "    langchain_available = False\n",
    "\n",
    "import torch\n",
    "print(f\"🔧 PyTorch: {torch.__version__}\")\n",
    "print(f\"🎮 CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Mémoire: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e89ac7",
   "metadata": {
    "papermill": {
     "duration": 0.006404,
     "end_time": "2025-09-29T08:40:56.221393",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.214989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Configuration des clés API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd1c400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.234998Z",
     "iopub.status.busy": "2025-09-29T08:40:56.234449Z",
     "iopub.status.idle": "2025-09-29T08:40:56.569239Z",
     "shell.execute_reply": "2025-09-29T08:40:56.568451Z"
    },
    "papermill": {
     "duration": 0.342965,
     "end_time": "2025-09-29T08:40:56.570586",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.227621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    OPENAI_API_KEY = user_secrets.get_secret(\"OPENAI_API_KEY\")\n",
    "    ASSEMBLYAI_API_KEY = user_secrets.get_secret(\"ASSEMBLYAI_API_KEY\")\n",
    "    HUGGINGFACE_TOKEN = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "    GROQ_API_KEY = user_secrets.get_secret(\"GROQ_API_KEY\")\n",
    "except:\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "    ASSEMBLYAI_API_KEY = os.environ.get(\"ASSEMBLYAI_API_KEY\", \"\")\n",
    "    HUGGINGFACE_TOKEN = os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
    "    GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642fe56",
   "metadata": {
    "papermill": {
     "duration": 0.006877,
     "end_time": "2025-09-29T08:40:56.584206",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.577329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Configuration des chemins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f87778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.598381Z",
     "iopub.status.busy": "2025-09-29T08:40:56.597771Z",
     "iopub.status.idle": "2025-09-29T08:40:56.600953Z",
     "shell.execute_reply": "2025-09-29T08:40:56.600467Z"
    },
    "papermill": {
     "duration": 0.011234,
     "end_time": "2025-09-29T08:40:56.602013",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.590779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "UPLOAD_PATH = \"/kaggle/input/meeting-audio/\" # Chemin des fichiers uploadés \n",
    "OUTPUT_PATH = \"/kaggle/working\" # Chemin de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e81951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.615858Z",
     "iopub.status.busy": "2025-09-29T08:40:56.615666Z",
     "iopub.status.idle": "2025-09-29T08:40:56.619137Z",
     "shell.execute_reply": "2025-09-29T08:40:56.618560Z"
    },
    "papermill": {
     "duration": 0.011917,
     "end_time": "2025-09-29T08:40:56.620315",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.608398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG_PATH = Path(OUTPUT_PATH) / \"debug\"\n",
    "DEBUG_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53420f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.633939Z",
     "iopub.status.busy": "2025-09-29T08:40:56.633724Z",
     "iopub.status.idle": "2025-09-29T08:40:56.637582Z",
     "shell.execute_reply": "2025-09-29T08:40:56.637065Z"
    },
    "papermill": {
     "duration": 0.011974,
     "end_time": "2025-09-29T08:40:56.638637",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.626663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEMP_DIR = Path(OUTPUT_PATH) / \"temp_chunks\"\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def cleanup_temp_files():\n",
    "    \"\"\"Nettoyer les fichiers temporaires\"\"\"\n",
    "    if TEMP_DIR.exists():\n",
    "        shutil.rmtree(TEMP_DIR)\n",
    "    TEMP_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb250fcd",
   "metadata": {
    "papermill": {
     "duration": 0.006385,
     "end_time": "2025-09-29T08:40:56.651824",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.645439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Utilitaires de commande système**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb2f257c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.666720Z",
     "iopub.status.busy": "2025-09-29T08:40:56.665963Z",
     "iopub.status.idle": "2025-09-29T08:40:56.670850Z",
     "shell.execute_reply": "2025-09-29T08:40:56.670186Z"
    },
    "papermill": {
     "duration": 0.013618,
     "end_time": "2025-09-29T08:40:56.671894",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.658276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_dir(p): \n",
    "    Path(p).mkdir(parents=True, exist_ok=True) #Vérification création de dossier\n",
    "    \n",
    "def run(cmd): # Lancement commande\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, err = p.communicate()\n",
    "    return p.returncode, out.decode(), err.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9495b963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.687106Z",
     "iopub.status.busy": "2025-09-29T08:40:56.686513Z",
     "iopub.status.idle": "2025-09-29T08:40:56.690546Z",
     "shell.execute_reply": "2025-09-29T08:40:56.689856Z"
    },
    "papermill": {
     "duration": 0.012662,
     "end_time": "2025-09-29T08:40:56.691671",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.679009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        free, total = torch.cuda.mem_get_info()\n",
    "        print(f\"📊 GPU: {free/1e9:.2f}GB libres / {total/1e9:.2f}GB total\")\n",
    "        if free < 4e9:  # Moins de 4GB libres\n",
    "            print(\"⚠️ Mémoire GPU faible, utilisation de 'base' recommandée\")\n",
    "            return \"medium\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ddf595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.706433Z",
     "iopub.status.busy": "2025-09-29T08:40:56.705873Z",
     "iopub.status.idle": "2025-09-29T08:40:56.713569Z",
     "shell.execute_reply": "2025-09-29T08:40:56.712864Z"
    },
    "papermill": {
     "duration": 0.01619,
     "end_time": "2025-09-29T08:40:56.714619",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.698429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_debug_json(data: Dict, step_name: str, timestamp: Optional[str] = None) -> str:\n",
    "    \"\"\"Sauvegarde JSON de debug pour chaque étape\"\"\"\n",
    "    if not config.save_intermediate_json:\n",
    "        return \"\"\n",
    "    \n",
    "    if timestamp is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    filename = f\"{step_name}_{timestamp}.json\"\n",
    "    filepath = DEBUG_PATH / filename\n",
    "    \n",
    "    # Créer un résumé pour les données volumineuses\n",
    "    debug_data = {\n",
    "        \"step\": step_name,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"status\": data.get(\"status\", \"unknown\"),\n",
    "        \"summary\": {}\n",
    "    }\n",
    "    \n",
    "    if \"segments\" in data and isinstance(data[\"segments\"], list):\n",
    "        debug_data[\"summary\"][\"total_segments\"] = len(data[\"segments\"])\n",
    "        debug_data[\"summary\"][\"sample_segments\"] = data[\"segments\"][:3] if data[\"segments\"] else []\n",
    "        debug_data[\"segments_count\"] = len(data[\"segments\"])\n",
    "    \n",
    "    if \"transcription\" in data:\n",
    "        debug_data[\"summary\"][\"text_length\"] = len(data[\"transcription\"])\n",
    "        debug_data[\"summary\"][\"text_preview\"] = data[\"transcription\"][:500] + \"...\" if len(data[\"transcription\"]) > 500 else data[\"transcription\"]\n",
    "    \n",
    "    if \"transcription_postprocessed\" in data:\n",
    "        debug_data[\"summary\"][\"postprocessed_length\"] = len(data[\"transcription_postprocessed\"])\n",
    "        debug_data[\"summary\"][\"postprocessed_preview\"] = data[\"transcription_postprocessed\"][:500] + \"...\"\n",
    "    \n",
    "    if \"transcription_llm\" in data:\n",
    "        debug_data[\"summary\"][\"llm_length\"] = len(data[\"transcription_llm\"])\n",
    "        debug_data[\"summary\"][\"llm_preview\"] = data[\"transcription_llm\"][:500] + \"...\"\n",
    "        debug_data[\"llm_correction_rate\"] = data.get(\"llm_correction_rate\", 0)\n",
    "    \n",
    "    # Ajouter les métadonnées complètes\n",
    "    debug_data[\"full_data_keys\"] = list(data.keys())\n",
    "    \n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(debug_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"📁 Debug JSON sauvé: {filepath}\")\n",
    "    return str(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f374502c",
   "metadata": {
    "papermill": {
     "duration": 0.006615,
     "end_time": "2025-09-29T08:40:56.727764",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.721149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Monitoring et debug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ea7a3ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.741663Z",
     "iopub.status.busy": "2025-09-29T08:40:56.740998Z",
     "iopub.status.idle": "2025-09-29T08:40:56.745369Z",
     "shell.execute_reply": "2025-09-29T08:40:56.744610Z"
    },
    "papermill": {
     "duration": 0.01238,
     "end_time": "2025-09-29T08:40:56.746486",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.734106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_memory_usage(step_name: str = \"\"):\n",
    "    \"\"\"Afficher l'utilisation mémoire\"\"\"\n",
    "    prefix = f\"[{step_name}] \" if step_name else \"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"{prefix}GPU Memory: {torch.cuda.memory_allocated()/1e9:.2f}GB / {torch.cuda.max_memory_allocated()/1e9:.2f}GB\")\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    print(f\"{prefix}RAM Usage: {process.memory_info().rss / 1e9:.2f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c09bcf",
   "metadata": {
    "papermill": {
     "duration": 0.006379,
     "end_time": "2025-09-29T08:40:56.759521",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.753142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Configuration du pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21574a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.773207Z",
     "iopub.status.busy": "2025-09-29T08:40:56.772725Z",
     "iopub.status.idle": "2025-09-29T08:40:56.777604Z",
     "shell.execute_reply": "2025-09-29T08:40:56.776920Z"
    },
    "papermill": {
     "duration": 0.01281,
     "end_time": "2025-09-29T08:40:56.778647",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.765837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimal_model_size() -> str:\n",
    "    \"\"\"\n",
    "    Détermine automatiquement la taille du modèle Whisper selon les ressources.\n",
    "    Adapté du projet SIIS pour une meilleure gestion mémoire.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            total_mem = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)\n",
    "        except:\n",
    "            total_mem = 0\n",
    "        \n",
    "        if total_mem >= 12:\n",
    "            return \"large-v3\"\n",
    "        elif total_mem >= 8:\n",
    "            return \"medium\"\n",
    "        elif total_mem >= 4:\n",
    "            return \"small\"\n",
    "        else:\n",
    "            return \"base\"\n",
    "    \n",
    "    # Mode CPU\n",
    "    if psutil is not None:\n",
    "        try:\n",
    "            ram_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "        except:\n",
    "            ram_gb = 0\n",
    "    else:\n",
    "        ram_gb = 8  # Défaut conservateur\n",
    "    \n",
    "    if ram_gb >= 16:\n",
    "        return \"small\"\n",
    "    elif ram_gb >= 8:\n",
    "        return \"base\"\n",
    "    else:\n",
    "        return \"tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8ca571f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.792834Z",
     "iopub.status.busy": "2025-09-29T08:40:56.792618Z",
     "iopub.status.idle": "2025-09-29T08:40:56.801448Z",
     "shell.execute_reply": "2025-09-29T08:40:56.800800Z"
    },
    "papermill": {
     "duration": 0.017306,
     "end_time": "2025-09-29T08:40:56.802459",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.785153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration: Whisper large-v3 | Device: cuda\n",
      "   Chunking: 900s | Condition on previous: False\n"
     ]
    }
   ],
   "source": [
    "@dataclass \n",
    "class Config: \n",
    "    \"\"\"Configuration centralisée pour Kaggle\"\"\" \n",
    "    \n",
    "    timezone: str = \"Indian/Antananarivo\"\n",
    "\n",
    "    # Debug\n",
    "    debug_mode: bool = True\n",
    "    save_intermediate_json: bool = True\n",
    "    \n",
    "    # Clés API \n",
    "    openai_key: str = OPENAI_API_KEY \n",
    "    assemblyai_key: str = ASSEMBLYAI_API_KEY\n",
    "    huggingface_token: str = HUGGINGFACE_TOKEN\n",
    "    \n",
    "    # Whisper\n",
    "    whisper_model: str = get_optimal_model_size() # 'tiny', 'base', 'small', 'medium', 'large', \"large-v3\"\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    compute_type: str = \"float16\" if torch.cuda.is_available() else \"int8\"\n",
    "    num_workers: int = 4\n",
    "    \n",
    "    # Audio\n",
    "    sample_rate: int = 16000\n",
    "    \n",
    "    # Decoding / anti-hallucination\n",
    "    beam_size: int = 5\n",
    "    best_of: int = 5\n",
    "    patience: float = 1.0\n",
    "    temperature: float = 0.0\n",
    "    compression_ratio_threshold: float = 2.4\n",
    "    log_prob_threshold: float = -1.0\n",
    "    no_speech_threshold: float = 0.6\n",
    "    condition_on_previous_text: bool = False\n",
    "    suppress_blank: bool = True\n",
    "    suppress_tokens: list[int] = field(default_factory=lambda: [-1])\n",
    "    max_initial_timestamp: float = 1.0\n",
    "    \n",
    "    # VAD\n",
    "    use_vad: bool = True\n",
    "    vad_threshold: float = 0.5\n",
    "    vad_min_speech_duration_ms: int = 250\n",
    "    vad_max_speech_duration_s: float = float('inf')\n",
    "    vad_min_silence_duration_ms: int = 2000\n",
    "    vad_speech_pad_ms: int = 400\n",
    "    \n",
    "    # Chunks longs pour cohérence (3–5 min)\n",
    "    chunk_length_s: int = 900\n",
    "    chunk_overlap_s: int = 30\n",
    "    \n",
    "    # Post-traitement\n",
    "    max_repetitions: int = 3\n",
    "    \n",
    "    # Prompt spécialisé\n",
    "    initial_prompt: str = (\n",
    "        \"Transcription d'une réunion du conseil d'administration à Madagascar. \"\n",
    "        \"Vocabulaire: conseil d'administration, procès-verbal, quorum, \"\n",
    "        \"résolution, délibération, vote, ordre du jour, budget, \"\n",
    "        \"millions d'Ariary, rapport financier. \"\n",
    "        \"Termes spécifiques: Fihariana, SON'INVEST, UNIMA, AQUALMA. \"\n",
    "        \"Format: discours naturel sans répétitions ni hallucinations.\"\n",
    "    )\n",
    "    \n",
    "    # LLM (activé par défaut en production)\n",
    "    enable_llm: bool = True\n",
    "    use_groq: bool = True\n",
    "    groq_model: str = \"llama-3.3-70b-versatile\"  # ou \"llama-3.3-70b-versatile\"\n",
    "    openai_model: str = \"gpt-4o-mini\" # \"gpt-3.5-turbo\" : Plus économique que GPT-4 # Fallback\n",
    "    max_correction_rate: float = 0.18\n",
    "    chunk_size_chars: int = 1000\n",
    "    chunk_overlap_chars: int = 200\n",
    "\n",
    "config = Config() \n",
    "\n",
    "print(f\"✅ Configuration: Whisper {config.whisper_model} | Device: {config.device}\")\n",
    "print(f\"   Chunking: {config.chunk_length_s}s | Condition on previous: {config.condition_on_previous_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a139fe8e",
   "metadata": {
    "papermill": {
     "duration": 0.006395,
     "end_time": "2025-09-29T08:40:56.815168",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.808773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Comment régler les paramètres selon les cas***\n",
    "\n",
    "Cas A — Audio propre (dictaphones, salle calme)\n",
    "*  beam_size=3, best_of=1–2 (plus rapide)\n",
    "* no_speech_threshold=0.6 (ok)\n",
    "* temperature=0.0\n",
    "* VAD : min_silence_duration_ms=1500\n",
    "\n",
    "Cas B — Audio bruité (portes, brouhaha)\n",
    "* beam_size=5, best_of=5 (qualité)\n",
    "* baisser no_speech_threshold à 0.5 si coupures\n",
    "* VAD : threshold=0.4–0.5, min_speech_duration_ms=200, min_silence_duration_ms=1800–2200\n",
    "* Garde-fous : garder compression_ratio_threshold=2.4\n",
    "\n",
    "Cas C — CPU-only (pas de GPU Kaggle)\n",
    "* compute_type=\"int8\", modèle tiny ou base\n",
    "* beam_size=3, best_of=1\n",
    "* Threads : cpu_threads=2, num_workers=1\n",
    "* Attends un RTF ≈ 2–5 (selon longueur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a580f82",
   "metadata": {
    "papermill": {
     "duration": 0.006165,
     "end_time": "2025-09-29T08:40:56.827548",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.821383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Préparation de l'audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cdca6c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.841156Z",
     "iopub.status.busy": "2025-09-29T08:40:56.840899Z",
     "iopub.status.idle": "2025-09-29T08:40:56.845339Z",
     "shell.execute_reply": "2025-09-29T08:40:56.844687Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.012298,
     "end_time": "2025-09-29T08:40:56.846349",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.834051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def slice_audio(input_path: str, output_path: str, start: float = 0.0, duration: Optional[int] = None) -> str:\n",
    "    args = [\"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"error\",\"-ss\",str(start),\"-i\",input_path,\"-ac\",\"1\",\"-ar\",str(config.sample_rate)]\n",
    "    if duration and duration > 0:\n",
    "        args += [\"-t\",str(duration)]\n",
    "    args += [output_path]\n",
    "    ensure_dir(str(Path(output_path).parent))\n",
    "    code, _, err = run(args)\n",
    "    if code!=0:\n",
    "        raise RuntimeError(\"FFmpeg slice failed: \" + err)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55d2ac",
   "metadata": {
    "papermill": {
     "duration": 0.006259,
     "end_time": "2025-09-29T08:40:56.858954",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.852695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Préprocessing et Débruitage Audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5327288f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.872874Z",
     "iopub.status.busy": "2025-09-29T08:40:56.872320Z",
     "iopub.status.idle": "2025-09-29T08:40:56.878125Z",
     "shell.execute_reply": "2025-09-29T08:40:56.877596Z"
    },
    "papermill": {
     "duration": 0.013695,
     "end_time": "2025-09-29T08:40:56.879006",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.865311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioPreprocessor:\n",
    "    \"\"\"Prétraitement audio avec FFmpeg et réduction de bruit\"\"\"\n",
    "    \n",
    "    def __init__(self, sample_rate: int = 16000):\n",
    "        self.sample_rate = sample_rate\n",
    "    \n",
    "    def ffmpeg_enhance(self, input_path: str, output_path: str):\n",
    "        \"\"\"Améliore l'audio avec FFmpeg\"\"\"\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-i\", input_path,\n",
    "            \"-ac\", \"1\",  # Mono\n",
    "            \"-ar\", str(self.sample_rate),  # 16kHz\n",
    "            \"-af\", \"highpass=f=200,lowpass=f=3000,afftdn=nf=-20\",  # Filtres\n",
    "            output_path\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True)\n",
    "    \n",
    "    def reduce_noise(self, input_path: str, output_path: str):\n",
    "        \"\"\"Réduit le bruit avec noisereduce\"\"\"\n",
    "        y, sr = librosa.load(input_path, sr=self.sample_rate)\n",
    "        y_clean = nr.reduce_noise(y=y, sr=sr, stationary=True, prop_decrease=0.8)\n",
    "        sf.write(output_path, y_clean, sr)\n",
    "        return output_path\n",
    "    \n",
    "    def process(self, input_path: str, output_dir: str) -> str:\n",
    "        \"\"\"Pipeline complet de prétraitement\"\"\"\n",
    "        base_name = Path(input_path).stem\n",
    "        ffmpeg_path = str(Path(output_dir) / f\"{base_name}_ffmpeg.wav\")\n",
    "        denoise_path = str(Path(output_dir) / f\"{base_name}_clean.wav\")\n",
    "        \n",
    "        self.ffmpeg_enhance(input_path, ffmpeg_path)\n",
    "        self.reduce_noise(ffmpeg_path, denoise_path)\n",
    "        \n",
    "        # Nettoyage fichier intermédiaire\n",
    "        if Path(ffmpeg_path).exists():\n",
    "            Path(ffmpeg_path).unlink()\n",
    "        \n",
    "        return denoise_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a001c329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.893301Z",
     "iopub.status.busy": "2025-09-29T08:40:56.892645Z",
     "iopub.status.idle": "2025-09-29T08:40:56.897497Z",
     "shell.execute_reply": "2025-09-29T08:40:56.896990Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.012947,
     "end_time": "2025-09-29T08:40:56.898488",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.885541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_audio_file(audio_path: str) -> Dict:\n",
    "    \"\"\"Prépare et valide le fichier audio pour la transcription\"\"\"\n",
    "    file_info = {\n",
    "        \"path\": audio_path,\n",
    "        \"exists\": os.path.exists(audio_path),\n",
    "        \"size_mb\": 0,\n",
    "        \"duration_seconds\": 0,\n",
    "        \"format\": audio_path.split('.')[-1],\n",
    "        \"sample_rate\": 0,\n",
    "        \"channels\": 0\n",
    "    }\n",
    "    \n",
    "    if file_info[\"exists\"]:\n",
    "        file_info[\"size_mb\"] = os.path.getsize(audio_path) / (1024 * 1024)\n",
    "        \n",
    "        try:\n",
    "            y, sr = librosa.load(audio_path, sr=None, duration=10)\n",
    "            file_info[\"sample_rate\"] = sr\n",
    "            duration = librosa.get_duration(path=audio_path)\n",
    "            file_info[\"duration_seconds\"] = duration\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erreur lecture audio: {e}\")\n",
    "    \n",
    "    return file_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7464c6",
   "metadata": {
    "papermill": {
     "duration": 0.006413,
     "end_time": "2025-09-29T08:40:56.911574",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.905161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Transcription Audio**\n",
    "**Service de transcription avec audio nettoyé**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0da88e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.925614Z",
     "iopub.status.busy": "2025-09-29T08:40:56.925398Z",
     "iopub.status.idle": "2025-09-29T08:40:56.938890Z",
     "shell.execute_reply": "2025-09-29T08:40:56.938203Z"
    },
    "papermill": {
     "duration": 0.022043,
     "end_time": "2025-09-29T08:40:56.939968",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.917925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranscriptionService:\n",
    "    \"\"\"Service de transcription avec configurations SIIS optimisées\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.model = None\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Charge le modèle Whisper avec gestion mémoire\"\"\"\n",
    "        if self.model is None:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            self.model = WhisperModel(\n",
    "                self.cfg.whisper_model,\n",
    "                device=self.cfg.device,\n",
    "                compute_type=self.cfg.compute_type,\n",
    "                num_workers=self.cfg.num_workers,  # 4 au lieu de 1\n",
    "                cpu_threads=4 if self.cfg.device == \"cpu\" else 0\n",
    "            )\n",
    "        return self.model\n",
    "    \n",
    "    def unload_model(self):\n",
    "        \"\"\"Libère le modèle de la mémoire\"\"\"\n",
    "        if self.model is not None:\n",
    "            del self.model\n",
    "            self.model = None\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    def transcribe_chunk(self, audio_path: str) -> Tuple[List, Dict]:\n",
    "        \"\"\"Transcrit un chunk audio\"\"\"\n",
    "        model = self.load_model()\n",
    "        \n",
    "        segments, info = model.transcribe(\n",
    "            audio_path,\n",
    "            language=\"fr\",\n",
    "            beam_size=self.cfg.beam_size,\n",
    "            best_of=self.cfg.best_of,\n",
    "            patience=self.cfg.patience,\n",
    "            temperature=self.cfg.temperature,\n",
    "            compression_ratio_threshold=self.cfg.compression_ratio_threshold,\n",
    "            log_prob_threshold=self.cfg.log_prob_threshold,\n",
    "            no_speech_threshold=self.cfg.no_speech_threshold,\n",
    "            condition_on_previous_text=self.cfg.condition_on_previous_text,  # TRUE!\n",
    "            initial_prompt=self.cfg.initial_prompt,\n",
    "            word_timestamps=True,\n",
    "            suppress_tokens=self.cfg.suppress_tokens,\n",
    "            suppress_blank=self.cfg.suppress_blank,\n",
    "            max_initial_timestamp=self.cfg.max_initial_timestamp,\n",
    "            vad_filter=self.cfg.use_vad,\n",
    "            vad_parameters={\n",
    "                \"threshold\": self.cfg.vad_threshold,\n",
    "                \"min_speech_duration_ms\": self.cfg.vad_min_speech_duration_ms,\n",
    "                \"max_speech_duration_s\": self.cfg.vad_max_speech_duration_s,\n",
    "                \"min_silence_duration_ms\": self.cfg.vad_min_silence_duration_ms,\n",
    "                \"speech_pad_ms\": self.cfg.vad_speech_pad_ms,\n",
    "            } if self.cfg.use_vad else None\n",
    "        )\n",
    "        \n",
    "        return list(segments), info\n",
    "    \n",
    "    def transcribe_long_audio(self, audio_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Transcrit un audio long avec chunking optimisé SIIS\n",
    "        Chunks de 900s au lieu de 180-300s pour moins de dérive\n",
    "        \"\"\"\n",
    "        # Obtenir la durée totale\n",
    "        y, sr = librosa.load(audio_path, sr=self.cfg.sample_rate, duration=1)\n",
    "        info = sf.info(audio_path)\n",
    "        total_duration = info.duration\n",
    "        \n",
    "        # Calcul des chunks\n",
    "        chunk_length = self.cfg.chunk_length_s\n",
    "        chunk_overlap = self.cfg.chunk_overlap_s\n",
    "        num_chunks = max(1, ceil(total_duration / chunk_length))\n",
    "        \n",
    "        print(f\"📊 Audio: {total_duration:.1f}s | {num_chunks} chunks de {chunk_length}s\")\n",
    "        \n",
    "        all_segments = []\n",
    "        all_text = []\n",
    "        \n",
    "        for i in range(num_chunks):\n",
    "            start_time = max(0, i * chunk_length - (chunk_overlap if i > 0 else 0))\n",
    "            duration = min(chunk_length + chunk_overlap, total_duration - start_time)\n",
    "            \n",
    "            # Extraire le chunk avec ffmpeg\n",
    "            chunk_path = str(TEMP_DIR / f\"chunk_{i:04d}.wav\")\n",
    "            cmd = [\n",
    "                \"ffmpeg\", \"-y\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "                \"-ss\", str(start_time),\n",
    "                \"-t\", str(duration),\n",
    "                \"-i\", audio_path,\n",
    "                \"-ac\", \"1\",\n",
    "                \"-ar\", str(self.cfg.sample_rate),\n",
    "                chunk_path\n",
    "            ]\n",
    "            subprocess.run(cmd, check=True)\n",
    "            \n",
    "            # Transcrire le chunk\n",
    "            print(f\"  Chunk {i+1}/{num_chunks}: {start_time:.1f}s - {start_time+duration:.1f}s\")\n",
    "            segments, chunk_info = self.transcribe_chunk(chunk_path)\n",
    "            \n",
    "            # Ajuster les timestamps\n",
    "            for seg in segments:\n",
    "                # Créer un nouveau dictionnaire pour chaque segment\n",
    "                segment_dict = {\n",
    "                    \"start\": seg.start + start_time,\n",
    "                    \"end\": seg.end + start_time,\n",
    "                    \"text\": seg.text.strip(),\n",
    "                }\n",
    "                \n",
    "                # Ajouter les mots avec timestamps ajustés si disponibles\n",
    "                if hasattr(seg, 'words') and seg.words:\n",
    "                    segment_dict[\"words\"] = [\n",
    "                        {\n",
    "                            \"start\": w.start + start_time,\n",
    "                            \"end\": w.end + start_time,\n",
    "                            \"word\": w.word,\n",
    "                            \"probability\": getattr(w, 'probability', 0.0)\n",
    "                        }\n",
    "                        for w in seg.words\n",
    "                    ]\n",
    "                \n",
    "                # Ajouter d'autres métadonnées si disponibles\n",
    "                if hasattr(seg, 'no_speech_prob'):\n",
    "                    segment_dict[\"no_speech_prob\"] = seg.no_speech_prob\n",
    "                if hasattr(seg, 'avg_logprob'):\n",
    "                    segment_dict[\"avg_logprob\"] = seg.avg_logprob\n",
    "                if hasattr(seg, 'compression_ratio'):\n",
    "                    segment_dict[\"compression_ratio\"] = seg.compression_ratio\n",
    "                \n",
    "                all_segments.append(segment_dict)\n",
    "                all_text.append(seg.text.strip())\n",
    "            \n",
    "            # Nettoyer le chunk temporaire\n",
    "            Path(chunk_path).unlink()\n",
    "        \n",
    "        # Assembler le résultat\n",
    "        result = {\n",
    "            \"status\": \"success\",\n",
    "            \"duration\": total_duration,\n",
    "            \"language\": \"fr\",\n",
    "            \"segments\": all_segments,\n",
    "            \"text\": \" \".join(all_text),\n",
    "            \"metadata\": {\n",
    "                \"model\": self.cfg.whisper_model,\n",
    "                \"chunks\": num_chunks,\n",
    "                \"chunk_length\": chunk_length,\n",
    "                \"condition_on_previous\": self.cfg.condition_on_previous_text\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b59f33f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.954123Z",
     "iopub.status.busy": "2025-09-29T08:40:56.953453Z",
     "iopub.status.idle": "2025-09-29T08:40:56.956545Z",
     "shell.execute_reply": "2025-09-29T08:40:56.955981Z"
    },
    "papermill": {
     "duration": 0.011152,
     "end_time": "2025-09-29T08:40:56.957589",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.946437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "#result = transcription_service.transcribe_audio(audio_file)\n",
    "#print(f\"Transcription: {result['transcription'][:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78625780",
   "metadata": {
    "papermill": {
     "duration": 0.006536,
     "end_time": "2025-09-29T08:40:56.970929",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.964393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Diarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b49eca33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:56.985158Z",
     "iopub.status.busy": "2025-09-29T08:40:56.984879Z",
     "iopub.status.idle": "2025-09-29T08:40:56.992830Z",
     "shell.execute_reply": "2025-09-29T08:40:56.992182Z"
    },
    "papermill": {
     "duration": 0.016287,
     "end_time": "2025-09-29T08:40:56.993821",
     "exception": false,
     "start_time": "2025-09-29T08:40:56.977534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diarize(transcription_data: Dict, audio_path: str, hf_token: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Diarisation avec pyannote (ou fallback whisperx)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from pyannote.audio import Pipeline\n",
    "        \n",
    "        print(\"🎙️ Diarisation avec pyannote...\")\n",
    "        pipeline = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=hf_token\n",
    "        )\n",
    "        \n",
    "        diarization = pipeline(audio_path)\n",
    "        \n",
    "        # Mapper les segments aux locuteurs\n",
    "        segments_with_speakers = []\n",
    "        for seg in transcription_data.get(\"segments\", []):\n",
    "            start, end = seg[\"start\"], seg[\"end\"]\n",
    "            \n",
    "            # Trouver le locuteur majoritaire pour ce segment\n",
    "            speaker_times = {}\n",
    "            for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "                overlap_start = max(start, turn.start)\n",
    "                overlap_end = min(end, turn.end)\n",
    "                if overlap_start < overlap_end:\n",
    "                    overlap_duration = overlap_end - overlap_start\n",
    "                    speaker_times[speaker] = speaker_times.get(speaker, 0) + overlap_duration\n",
    "            \n",
    "            # Assigner le locuteur avec le plus de temps de parole\n",
    "            if speaker_times:\n",
    "                main_speaker = max(speaker_times, key=speaker_times.get)\n",
    "                seg[\"speaker\"] = main_speaker\n",
    "            else:\n",
    "                seg[\"speaker\"] = \"Unknown\"\n",
    "            \n",
    "            segments_with_speakers.append(seg)\n",
    "        \n",
    "        transcription_data[\"segments_diarized\"] = segments_with_speakers\n",
    "        transcription_data[\"diarization_method\"] = \"pyannote\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Diarisation pyannote échouée: {e}\")\n",
    "        \n",
    "        # Fallback sur whisperx si disponible\n",
    "        try:\n",
    "            import whisperx\n",
    "            print(\"🔄 Fallback sur whisperx...\")\n",
    "            \n",
    "            # Aligner avec whisperx\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            align_model, metadata = whisperx.load_align_model(\n",
    "                language_code=\"fr\",\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            result_aligned = whisperx.align(\n",
    "                transcription_data[\"segments\"],\n",
    "                align_model,\n",
    "                metadata,\n",
    "                audio_path,\n",
    "                device\n",
    "            )\n",
    "            \n",
    "            # Diarisation\n",
    "            diarize_model = whisperx.DiarizationPipeline(use_auth_token=hf_token)\n",
    "            diarize_segments = diarize_model(audio_path)\n",
    "            result_diarized = whisperx.assign_word_speakers(diarize_segments, result_aligned)\n",
    "            \n",
    "            transcription_data[\"segments_diarized\"] = result_diarized[\"segments\"]\n",
    "            transcription_data[\"diarization_method\"] = \"whisperx\"\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"⚠️ Diarisation whisperx échouée: {e2}\")\n",
    "            transcription_data[\"diarization_method\"] = \"none\"\n",
    "    \n",
    "    return transcription_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9aa83b",
   "metadata": {
    "papermill": {
     "duration": 0.006324,
     "end_time": "2025-09-29T08:40:57.006427",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.000103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Post-traitement du texte**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2a262f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:57.062113Z",
     "iopub.status.busy": "2025-09-29T08:40:57.061554Z",
     "iopub.status.idle": "2025-09-29T08:40:57.067310Z",
     "shell.execute_reply": "2025-09-29T08:40:57.066672Z"
    },
    "papermill": {
     "duration": 0.055523,
     "end_time": "2025-09-29T08:40:57.068303",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.012780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_numbers_and_units(text: str) -> str:\n",
    "    \"\"\"Normalise les nombres et unités monétaires\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Normaliser les millions\n",
    "    text = re.sub(r'(\\d+)\\s*,\\s*(\\d+)\\s*millions?', r'\\1.\\2 millions', text)\n",
    "    text = re.sub(r'(\\d+)\\s*virgule\\s*(\\d+)\\s*millions?', r'\\1.\\2 millions', text)\n",
    "    \n",
    "    # Ajouter Ariary si manquant après les montants\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*millions?\\s*(?!d\\'?[Aa]riary)', r'\\1 millions d\\'Ariary', text)\n",
    "    \n",
    "    # Normaliser les pourcentages\n",
    "    text = re.sub(r'(\\d+)\\s*pour\\s*cent', r'\\1%', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def deduplicate_sentences(text: str) -> str:\n",
    "    \"\"\"Supprime les répétitions de phrases\"\"\"\n",
    "    import re\n",
    "    \n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    seen = set()\n",
    "    unique_sentences = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        sent_lower = sent.lower().strip()\n",
    "        if sent_lower and sent_lower not in seen:\n",
    "            seen.add(sent_lower)\n",
    "            unique_sentences.append(sent)\n",
    "    \n",
    "    return ' '.join(unique_sentences)\n",
    "\n",
    "def postprocess_text(text: str) -> str:\n",
    "    # Nettoyer les espaces multiples\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    text = normalize_numbers_and_units(text)\n",
    "    text = deduplicate_sentences(text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50fcc7e",
   "metadata": {
    "papermill": {
     "duration": 0.006259,
     "end_time": "2025-09-29T08:40:57.081137",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.074878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Nettoyage LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7527b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:57.094908Z",
     "iopub.status.busy": "2025-09-29T08:40:57.094724Z",
     "iopub.status.idle": "2025-09-29T08:40:57.104734Z",
     "shell.execute_reply": "2025-09-29T08:40:57.104256Z"
    },
    "papermill": {
     "duration": 0.018078,
     "end_time": "2025-09-29T08:40:57.105719",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.087641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LLMCleaner:\n",
    "    \"\"\"Nettoyage du texte avec LLM (Groq ou OpenAI)\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.client = None\n",
    "        \n",
    "        if cfg.use_groq and GROQ_API_KEY:\n",
    "            try:\n",
    "                from groq import Groq\n",
    "                self.client = Groq(api_key=GROQ_API_KEY)\n",
    "                self.provider = \"groq\"\n",
    "                print(\"✅ Utilisation de Groq pour le nettoyage LLM\")\n",
    "            except ImportError:\n",
    "                print(\"⚠️ Package groq non installé, installation...\")\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"groq\"])\n",
    "                from groq import Groq\n",
    "                self.client = Groq(api_key=GROQ_API_KEY)\n",
    "                self.provider = \"groq\"\n",
    "        elif OPENAI_API_KEY:\n",
    "            from openai import OpenAI\n",
    "            self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "            self.provider = \"openai\"\n",
    "            print(\"✅ Utilisation d'OpenAI pour le nettoyage LLM\")\n",
    "        else:\n",
    "            print(\"⚠️ Aucune clé API LLM disponible\")\n",
    "    \n",
    "    def create_chunks(self, text: str) -> List[str]:\n",
    "        \"\"\"Découpe le texte en chunks pour traitement LLM\"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        step = max(1, self.cfg.chunk_size_chars - self.cfg.chunk_overlap_chars)\n",
    "        chunks = []\n",
    "        for i in range(0, len(text), step):\n",
    "            chunks.append(text[i:i + self.cfg.chunk_size_chars])\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def clean_text(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"Nettoie le texte avec le LLM\"\"\"\n",
    "        if not self.client or not text:\n",
    "            return text, 0.0\n",
    "        \n",
    "        chunks = self.create_chunks(text)\n",
    "        cleaned_chunks = []\n",
    "        total_delta = 0\n",
    "        \n",
    "        system_prompt = \"\"\"Tu es un assistant de correction de transcription.\n",
    "            Tu corriges UNIQUEMENT : orthographe, grammaire, ponctuation, noms propres malgaches.\n",
    "            RÈGLES STRICTES :\n",
    "            1. NE JAMAIS ajouter d'information non présente\n",
    "            2. NE PAS changer le sens des phrases\n",
    "            3. Conserver tous les chiffres et montants exacts\n",
    "            Contexte: Réunion du conseil d'administration à Madagascar.\n",
    "            Termes valides: Fihariana, SON'INVEST, UNIMA, AQUALMA, Ariary.\"\"\"\n",
    "        \n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            print(f\"  Nettoyage chunk {i}/{len(chunks)}...\")\n",
    "            \n",
    "            try:\n",
    "                if self.provider == \"groq\":\n",
    "                    response = self.client.chat.completions.create(\n",
    "                        model=self.cfg.groq_model,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": system_prompt},\n",
    "                            {\"role\": \"user\", \"content\": f\"Corrige ce texte:\\n\\n{chunk}\"}\n",
    "                        ],\n",
    "                        temperature=0.2,\n",
    "                        max_tokens=1500\n",
    "                    )\n",
    "                    cleaned = response.choices[0].message.content.strip()\n",
    "                else:  # OpenAI\n",
    "                    response = self.client.chat.completions.create(\n",
    "                        model=self.cfg.openai_model,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": system_prompt},\n",
    "                            {\"role\": \"user\", \"content\": chunk}\n",
    "                        ],\n",
    "                        temperature=0.2,\n",
    "                        max_tokens=1400\n",
    "                    )\n",
    "                    cleaned = response.choices[0].message.content.strip()\n",
    "                \n",
    "                cleaned_chunks.append(cleaned)\n",
    "                total_delta += abs(len(cleaned) - len(chunk))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠️ Erreur LLM chunk {i}: {e}\")\n",
    "                cleaned_chunks.append(chunk)  # Garder l'original si erreur\n",
    "        \n",
    "        # Assembler et calculer le taux de correction\n",
    "        merged_text = ' '.join(cleaned_chunks)\n",
    "        correction_rate = total_delta / max(len(text), 1)\n",
    "        \n",
    "        # Vérifier le taux de correction\n",
    "        if correction_rate > self.cfg.max_correction_rate:\n",
    "            print(f\"⚠️ Taux de correction {correction_rate:.1%} > seuil {self.cfg.max_correction_rate:.0%}\")\n",
    "            print(\"   → Conservation du texte post-traité sans LLM\")\n",
    "            return text, correction_rate\n",
    "        \n",
    "        return merged_text, correction_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c4a158",
   "metadata": {
    "papermill": {
     "duration": 0.006208,
     "end_time": "2025-09-29T08:40:57.118382",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.112174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Fallback AssemblyAI (si échec Whisper)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e14cefeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:57.132430Z",
     "iopub.status.busy": "2025-09-29T08:40:57.131980Z",
     "iopub.status.idle": "2025-09-29T08:40:57.138611Z",
     "shell.execute_reply": "2025-09-29T08:40:57.137943Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014816,
     "end_time": "2025-09-29T08:40:57.139705",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.124889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AssemblyAIFallback:\n",
    "    \"\"\"Service de fallback avec AssemblyAI\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        \n",
    "    def transcribe_with_assemblyai(self, audio_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Transcription de secours via AssemblyAI\n",
    "        \n",
    "        Args:\n",
    "            audio_path: Chemin du fichier audio\n",
    "            \n",
    "        Returns:\n",
    "            Dict avec la transcription\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"Clé API AssemblyAI non configurée\"\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            import assemblyai as aai\n",
    "            \n",
    "            print(\"🔄 Utilisation du fallback AssemblyAI...\")\n",
    "            \n",
    "            aai.settings.api_key = self.api_key\n",
    "            transcriber = aai.Transcriber()\n",
    "            \n",
    "            # Upload et transcription\n",
    "            config_lang = aai.TranscriptionConfig(\n",
    "                language_code=\"fr\",\n",
    "                punctuate=True,\n",
    "                format_text=True,\n",
    "                disfluencies=True,\n",
    "                speaker_labels=True\n",
    "            )\n",
    "            transcript = transcriber.transcribe(audio_path, config=config_lang)\n",
    "            \n",
    "            if transcript.status == aai.TranscriptStatus.error:\n",
    "                raise Exception(f\"Erreur AssemblyAI: {transcript.error}\")\n",
    "            \n",
    "            # Attente de la transcription\n",
    "            while transcript.status not in [aai.TranscriptStatus.completed, aai.TranscriptStatus.error]:\n",
    "                time.sleep(5)\n",
    "                transcript = transcriber.get_transcript(transcript.id)\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"method\": \"assemblyai\",\n",
    "                \"transcription\": transcript.text,\n",
    "                \"confidence\": transcript.confidence if hasattr(transcript, 'confidence') else 0.85,\n",
    "                \"words\": transcript.words if hasattr(transcript, 'words') else []\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur AssemblyAI: {str(e)}\")\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"method\": \"assemblyai\"\n",
    "            }\n",
    "\n",
    "# Service de fallback\n",
    "fallback_service = AssemblyAIFallback(config.assemblyai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd71f44",
   "metadata": {
    "papermill": {
     "duration": 0.006361,
     "end_time": "2025-09-29T08:40:57.152552",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.146191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Par défaut, la langue est auto. Pour ton cas, force français :\n",
    "        config = aai.TranscriptionConfig(language_code=\"fr\")\n",
    "2. Diarisation (orateurs)\n",
    "        config = aai.TranscriptionConfig(speaker_labels=True)\n",
    "\n",
    "Exemple :\n",
    "    config = aai.TranscriptionConfig(language_code=\"fr\", speaker_labels=True)\n",
    "    transcript = transcriber.transcribe(audio_path, config=config)\n",
    "\n",
    "Appel :\n",
    "    Si TranscriptionService.transcribe_audio renvoie status=\"error\" ou un real_time_factor >> 5 (trop lent) ou trop de segments sous ton confidence_threshold, alors :\n",
    "        > result = fallback_service.transcribe_with_assemblyai(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d0ba5",
   "metadata": {
    "papermill": {
     "duration": 0.006383,
     "end_time": "2025-09-29T08:40:57.165370",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.158987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Pipeline de transcription avec gestion automatique du fallback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af684599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:57.178984Z",
     "iopub.status.busy": "2025-09-29T08:40:57.178784Z",
     "iopub.status.idle": "2025-09-29T08:40:57.190403Z",
     "shell.execute_reply": "2025-09-29T08:40:57.189712Z"
    },
    "papermill": {
     "duration": 0.019632,
     "end_time": "2025-09-29T08:40:57.191398",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.171766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transcribe_audio_pipeline(\n",
    "    audio_path: str,\n",
    "    cfg: Config,\n",
    "    save_json: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Pipeline complet optimisé de transcription\n",
    "    \n",
    "    Étapes:\n",
    "    1. Prétraitement audio (FFmpeg + débruitage)\n",
    "    2. Transcription avec chunking long (900s)\n",
    "    3. Diarisation des locuteurs\n",
    "    4. Post-traitement (normalisation, déduplications)\n",
    "    5. Nettoyage LLM avec Groq\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire avec toutes les versions de la transcription\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Initialisation\n",
    "        cleanup_temp_files()\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # [1/5] Prétraitement\n",
    "        print(\"\\n[1/5] 🔊 Prétraitement audio...\")\n",
    "        preprocessor = AudioPreprocessor(cfg.sample_rate)\n",
    "        clean_audio_path = preprocessor.process(audio_path, str(TEMP_DIR))\n",
    "        \n",
    "        # Libérer mémoire\n",
    "        del preprocessor\n",
    "        gc.collect()\n",
    "        \n",
    "        # [2/5] Transcription\n",
    "        print(\"\\n[2/5] 📝 Transcription avec Whisper...\")\n",
    "        service = TranscriptionService(cfg)\n",
    "        transcription_result = service.transcribe_long_audio(clean_audio_path)\n",
    "        \n",
    "        # Sauvegarder la transcription brute (02_transcription)\n",
    "        if save_json:\n",
    "            raw_output = {\n",
    "                \"timestamp\": timestamp,\n",
    "                \"status\": transcription_result[\"status\"],\n",
    "                \"duration\": transcription_result[\"duration\"],\n",
    "                \"text\": transcription_result[\"text\"],\n",
    "                \"segments\": transcription_result[\"segments\"],\n",
    "                \"metadata\": transcription_result[\"metadata\"]\n",
    "            }\n",
    "            raw_path = Path(OUTPUT_PATH) / f\"02_transcription_{timestamp}.json\"\n",
    "            with open(raw_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(raw_output, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"  💾 Sauvegardé: {raw_path}\")\n",
    "        \n",
    "        # Libérer le modèle\n",
    "        service.unload_model()\n",
    "        gc.collect()\n",
    "        \n",
    "        # [3/5] Diarisation\n",
    "        print(\"\\n[3/5] 🎙️ Diarisation des locuteurs...\")\n",
    "        if HUGGINGFACE_TOKEN:\n",
    "            transcription_result = diarize(\n",
    "                transcription_result,\n",
    "                clean_audio_path,\n",
    "                HUGGINGFACE_TOKEN\n",
    "            )\n",
    "            \n",
    "            # Sauvegarder avec diarisation (03_diarization)\n",
    "            if save_json and transcription_result.get(\"segments_diarized\"):\n",
    "                diar_output = {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"status\": \"success\",\n",
    "                    \"duration\": transcription_result[\"duration\"],\n",
    "                    \"diarization_method\": transcription_result.get(\"diarization_method\", \"none\"),\n",
    "                    \"segments\": transcription_result.get(\"segments_diarized\", transcription_result[\"segments\"]),\n",
    "                    \"text\": transcription_result[\"text\"]\n",
    "                }\n",
    "                diar_path = Path(OUTPUT_PATH) / f\"03_diarization_{timestamp}.json\"\n",
    "                with open(diar_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(diar_output, f, ensure_ascii=False, indent=2)\n",
    "                print(f\"  💾 Sauvegardé: {diar_path}\")\n",
    "        else:\n",
    "            print(\"  ⚠️ Token HuggingFace manquant, diarisation ignorée\")\n",
    "        \n",
    "        # [4/5] Post-traitement\n",
    "        print(\"\\n[4/5] 🔧 Post-traitement du texte...\")\n",
    "        text_postprocessed = postprocess_text(transcription_result[\"text\"])\n",
    "        print(f\"  Réduction: {len(transcription_result['text'])} → {len(text_postprocessed)} caractères\")\n",
    "        \n",
    "        # [5/5] Nettoyage LLM\n",
    "        print(\"\\n[5/5] ✨ Nettoyage LLM...\")\n",
    "        text_final = text_postprocessed\n",
    "        correction_rate = 0.0\n",
    "        \n",
    "        if cfg.enable_llm:\n",
    "            cleaner = LLMCleaner(cfg)\n",
    "            text_final, correction_rate = cleaner.clean_text(text_postprocessed)\n",
    "            print(f\"  Taux de correction: {correction_rate:.1%}\")\n",
    "        else:\n",
    "            print(\"  ℹ️ LLM désactivé\")\n",
    "        \n",
    "        # Résultat final\n",
    "        final_result = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"status\": \"success\",\n",
    "            \"duration\": transcription_result[\"duration\"],\n",
    "            \"model\": cfg.whisper_model,\n",
    "            \"transcription_raw\": transcription_result[\"text\"],\n",
    "            \"transcription_postprocessed\": text_postprocessed,\n",
    "            \"transcription_final\": text_final,\n",
    "            \"llm_correction_rate\": correction_rate,\n",
    "            \"llm_provider\": getattr(cleaner, 'provider', 'none') if cfg.enable_llm else 'none',\n",
    "            \"segments\": transcription_result.get(\"segments_diarized\", transcription_result[\"segments\"]),\n",
    "            \"metadata\": {\n",
    "                \"pipeline_version\": \"2.0-optimized\",\n",
    "                \"chunk_length\": cfg.chunk_length_s,\n",
    "                \"condition_on_previous\": cfg.condition_on_previous_text,\n",
    "                \"vad_enabled\": cfg.use_vad,\n",
    "                \"diarization\": transcription_result.get(\"diarization_method\", \"none\")\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Sauvegarder le résultat final\n",
    "        if save_json:\n",
    "            final_path = Path(OUTPUT_PATH) / f\"transcription_complete_{timestamp}.json\"\n",
    "            with open(final_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_result, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"\\n✅ Pipeline terminé! Résultats sauvegardés:\")\n",
    "            print(f\"   - {raw_path.name} (transcription brute)\")\n",
    "            #if HUGGINGFACE_TOKEN:\n",
    "                #print(f\"   - {diar_path.name} (avec diarisation)\")\n",
    "            print(f\"   - {final_path.name} (version finale)\")\n",
    "        \n",
    "        return final_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Erreur dans le pipeline: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\"status\": \"error\", \"error\": str(e)}\n",
    "    \n",
    "    finally:\n",
    "        cleanup_temp_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ccc320",
   "metadata": {
    "papermill": {
     "duration": 0.006357,
     "end_time": "2025-09-29T08:40:57.204218",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.197861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **EXÉCUTION PRINCIPALE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce389f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:57.217841Z",
     "iopub.status.busy": "2025-09-29T08:40:57.217500Z",
     "iopub.status.idle": "2025-09-29T08:40:57.220485Z",
     "shell.execute_reply": "2025-09-29T08:40:57.219841Z"
    },
    "papermill": {
     "duration": 0.010953,
     "end_time": "2025-09-29T08:40:57.221583",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.210630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test avec votre fichier audio\n",
    "#audio_file = f\"{UPLOAD_PATH}atelier.mp3\"\n",
    "#audio_file = f\"{UPLOAD_PATH}test_1h.wav\"\n",
    "audio_file = f\"{UPLOAD_PATH}test_30mn.mp3\"\n",
    "#audio_info = prepare_audio_file(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d36fd",
   "metadata": {
    "papermill": {
     "duration": 0.006346,
     "end_time": "2025-09-29T08:40:57.234562",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.228216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#**Analyse des Résultats de Debug**\n",
    "\n",
    "Les fichiers JSON de debug sont sauvegardés dans `/kaggle/working/debug_json/` avec le format:\n",
    "- `02_transcription_[timestamp].json` : Résultat brut de Whisper\n",
    "- `03_diarization_[timestamp].json` : Après identification des locuteurs\n",
    "- `04_postprocessing_[timestamp].json` : Après normalisation et déduplication\n",
    "- `05_llm_cleaning_[timestamp].json` : Version finale nettoyée par LLM\n",
    "\n",
    "Chaque fichier contient :\n",
    "- Un résumé (`summary`) avec aperçu du texte et statistiques\n",
    "- Les métadonnées de l'étape (`status`, `timestamp`)\n",
    "- Les données complètes peuvent être consultées dans le fichier principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1b65298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:57.248234Z",
     "iopub.status.busy": "2025-09-29T08:40:57.248013Z",
     "iopub.status.idle": "2025-09-29T08:44:53.359015Z",
     "shell.execute_reply": "2025-09-29T08:44:53.358180Z"
    },
    "papermill": {
     "duration": 236.119341,
     "end_time": "2025-09-29T08:44:53.360343",
     "exception": false,
     "start_time": "2025-09-29T08:40:57.241002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Fichier trouvé: test_30mn.mp3\n",
      "============================================================\n",
      "\n",
      "[1/5] 🔊 Prétraitement audio...\n",
      "\n",
      "[2/5] 📝 Transcription avec Whisper...\n",
      "📊 Audio: 1928.0s | 3 chunks de 900s\n",
      "  Chunk 1/3: 0.0s - 930.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c49b8ca46e4b8183e88b5ca34b82af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a596ff0a1e04e22aad8a9339fb20b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9cfbf1263641679d59db7725e05114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3557760ef34341fe8d9b44910aa8d3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571cd92111ca4c63b0759708d7184392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 2/3: 870.0s - 1800.0s\n",
      "  Chunk 3/3: 1770.0s - 1928.0s\n",
      "  💾 Sauvegardé: /kaggle/working/02_transcription_20250929_084057.json\n",
      "\n",
      "[3/5] 🎙️ Diarisation des locuteurs...\n",
      "⚠️ Diarisation pyannote échouée: No module named 'pyannote'\n",
      "⚠️ Diarisation whisperx échouée: No module named 'whisperx'\n",
      "\n",
      "[4/5] 🔧 Post-traitement du texte...\n",
      "  Réduction: 14897 → 14543 caractères\n",
      "\n",
      "[5/5] ✨ Nettoyage LLM...\n",
      "⚠️ Package groq non installé, installation...\n",
      "Collecting groq\n",
      "  Downloading groq-0.32.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
      "Downloading groq-0.32.0-py3-none-any.whl (135 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.4/135.4 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: groq\n",
      "Successfully installed groq-0.32.0\n",
      "  Nettoyage chunk 1/19...\n",
      "  Nettoyage chunk 2/19...\n",
      "  Nettoyage chunk 3/19...\n",
      "  Nettoyage chunk 4/19...\n",
      "  Nettoyage chunk 5/19...\n",
      "  Nettoyage chunk 6/19...\n",
      "  Nettoyage chunk 7/19...\n",
      "  Nettoyage chunk 8/19...\n",
      "  Nettoyage chunk 9/19...\n",
      "  Nettoyage chunk 10/19...\n",
      "  Nettoyage chunk 11/19...\n",
      "  Nettoyage chunk 12/19...\n",
      "  Nettoyage chunk 13/19...\n",
      "  Nettoyage chunk 14/19...\n",
      "  Nettoyage chunk 15/19...\n",
      "  Nettoyage chunk 16/19...\n",
      "  Nettoyage chunk 17/19...\n",
      "  Nettoyage chunk 18/19...\n",
      "  Nettoyage chunk 19/19...\n",
      "⚠️ Taux de correction 41.8% > seuil 18%\n",
      "   → Conservation du texte post-traité sans LLM\n",
      "  Taux de correction: 41.8%\n",
      "\n",
      "✅ Pipeline terminé! Résultats sauvegardés:\n",
      "   - 02_transcription_20250929_084057.json (transcription brute)\n",
      "   - transcription_complete_20250929_084057.json (version finale)\n",
      "\n",
      "============================================================\n",
      "📊 RÉSUMÉ DE LA TRANSCRIPTION\n",
      "============================================================\n",
      "Durée: 1928.0 secondes\n",
      "Modèle: large-v3\n",
      "Provider LLM: groq\n",
      "Taux correction LLM: 41.8%\n",
      "\n",
      "📝 Extrait (500 premiers caractères):\n",
      "----------------------------------------\n",
      "Par exemple, tous les étudiants, les professeurs, tous les membres de la communauté, nous avons le premier ordre d'ordre de la revue à NIPARCOURT et SINOTION, au printemps 12 août 2015. C'est la situation, une situation où on se rend compte qu'il y a une situation qui est en train de se rendre compte, donc on peut prendre la parole à l'interprète, pour qu'il puisse vous expliquer ce qui se passe. Pour ce vidéo que je vais vous présenter, c'est dans le profil d'estimation pour 31-12, le contexte ...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Rechercher le fichier audio\n",
    "    audio_files = list(Path(UPLOAD_PATH).glob(\"*.mp3\")) + \\\n",
    "                  list(Path(UPLOAD_PATH).glob(\"*.wav\")) + \\\n",
    "                  list(Path(UPLOAD_PATH).glob(\"*.m4a\"))\n",
    "    \n",
    "    if audio_files:\n",
    "        audio_file = audio_files[0]\n",
    "        print(f\"\\n📂 Fichier trouvé: {audio_file.name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Lancer le pipeline\n",
    "        result = transcribe_audio_pipeline(\n",
    "            str(audio_file),\n",
    "            config,\n",
    "            save_json=True\n",
    "        )\n",
    "        \n",
    "        # Afficher un résumé\n",
    "        if result[\"status\"] == \"success\":\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"📊 RÉSUMÉ DE LA TRANSCRIPTION\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Durée: {result['duration']:.1f} secondes\")\n",
    "            print(f\"Modèle: {result['model']}\")\n",
    "            print(f\"Provider LLM: {result.get('llm_provider', 'none')}\")\n",
    "            print(f\"Taux correction LLM: {result.get('llm_correction_rate', 0):.1%}\")\n",
    "            print(f\"\\n📝 Extrait (500 premiers caractères):\")\n",
    "            print(\"-\" * 40)\n",
    "            print(result['transcription_final'][:500] + \"...\")\n",
    "    else:\n",
    "        print(\"⚠️ Aucun fichier audio trouvé dans\", UPLOAD_PATH)\n",
    "        print(\"   Formats supportés: .mp3, .wav, .m4a\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8302666,
     "sourceId": 13136823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 277.146139,
   "end_time": "2025-09-29T08:44:57.082805",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-29T08:40:19.936666",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00d7dbf31a75463fb3149dd3a64c6d12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "069cc374856a4d2ea8a3fdc07238311a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a596ff0a1e04e22aad8a9339fb20b7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b29fedd489cd4686a1bb4216208b2f45",
        "IPY_MODEL_16da6e604bb34a83ade03e689c2a1df8",
        "IPY_MODEL_a48e82c6cabf4f8aa63d89206905ce33"
       ],
       "layout": "IPY_MODEL_e6464368dced437ebb28bd1864b0658b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0a9cfbf1263641679d59db7725e05114": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_44f78d8564184683b05e838b51ec1824",
        "IPY_MODEL_78005510f2744157a0c669185a105033",
        "IPY_MODEL_81ea59e20a2443f18299560cd63996ab"
       ],
       "layout": "IPY_MODEL_a43d49204047467898a0031668f20c79",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0ec7c406f5a445a99742dbb4d1b75fc9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0edf1b5e3a8145c29c027831d681f296": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "16da6e604bb34a83ade03e689c2a1df8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_00d7dbf31a75463fb3149dd3a64c6d12",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_555d9f40425d49cfad1503bb8b4b9f1d",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "217c857e60464e47980188d1d7938ee1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2245a61acaed4e05a838b01dd70759cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0ec7c406f5a445a99742dbb4d1b75fc9",
       "placeholder": "​",
       "style": "IPY_MODEL_a9aabd79ca6a4b949186ab04db0d83ca",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: "
      }
     },
     "24d6f8b894d4429095266581adfc9499": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f62f87608e343a7ab6a9891d9f7ecc2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3557760ef34341fe8d9b44910aa8d3ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3c77a6ddddaa45529e96811a8e097c2f",
        "IPY_MODEL_82a70913a42c4dcaa73a7cc601d40f37",
        "IPY_MODEL_be877d400cb14454b30ea0f3cdb90e56"
       ],
       "layout": "IPY_MODEL_c83ebd67ceb0412baf7a3ee9c54c79f8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3bd56f0eb80d4652bc7d0948544df8c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ebec22acec174f859df0cf4a43212148",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_91fafe489226430dab0a8cf8b6378f3e",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "3c77a6ddddaa45529e96811a8e097c2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ce6694af12b541d49cd5029a099530f3",
       "placeholder": "​",
       "style": "IPY_MODEL_e39956d6325c4037b3953a3ef5733dc1",
       "tabbable": null,
       "tooltip": null,
       "value": "preprocessor_config.json: 100%"
      }
     },
     "418906a372ba4dab84c8db5ce9721a3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41b9e1981954409e824fd46173da70ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "44f78d8564184683b05e838b51ec1824": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fd78cc95ae9c41bb929f83f8409a9949",
       "placeholder": "​",
       "style": "IPY_MODEL_cb006df9508e4bfd98034a61435aea68",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: "
      }
     },
     "555d9f40425d49cfad1503bb8b4b9f1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "571cd92111ca4c63b0759708d7184392": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fa8f0dba35de432da55a108ebb6dea6d",
        "IPY_MODEL_f8e18f6333ce407e883945a996cc7342",
        "IPY_MODEL_83c157ef0f384aaa878a2ad01529ad09"
       ],
       "layout": "IPY_MODEL_24d6f8b894d4429095266581adfc9499",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5af53e6aff03496290f52c3bfa429365": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "60ca70404f014c3ebf32087af6d1bb5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "620d22bab5ad468d9436a390bf46bffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63cf946809584b6a9ffd46d0285144c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "78005510f2744157a0c669185a105033": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f18c730737a9476eadb90fcadb2dd66a",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_94daae398c544b3980fcd6c4bdbf398e",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "7a33c7a9ef014cbda56e003a479ed552": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7caecfbcd79648079dab3f15d0cc9e0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_069cc374856a4d2ea8a3fdc07238311a",
       "placeholder": "​",
       "style": "IPY_MODEL_fe7b96962efd4ee281ff0ae9db983094",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.48M/? [00:00&lt;00:00, 28.4MB/s]"
      }
     },
     "7da76598d8ec45908cc57a310f3b42c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8125518bac594022a06297c8d7fdf93b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81ea59e20a2443f18299560cd63996ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e676886ea6794af387f3eece2baa7768",
       "placeholder": "​",
       "style": "IPY_MODEL_41b9e1981954409e824fd46173da70ea",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.39k/? [00:00&lt;00:00, 129kB/s]"
      }
     },
     "82a70913a42c4dcaa73a7cc601d40f37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2f62f87608e343a7ab6a9891d9f7ecc2",
       "max": 340.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_60ca70404f014c3ebf32087af6d1bb5b",
       "tabbable": null,
       "tooltip": null,
       "value": 340.0
      }
     },
     "83c157ef0f384aaa878a2ad01529ad09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_217c857e60464e47980188d1d7938ee1",
       "placeholder": "​",
       "style": "IPY_MODEL_b5351c0896b245d2b80211849535a172",
       "tabbable": null,
       "tooltip": null,
       "value": " 3.09G/3.09G [00:12&lt;00:00, 224MB/s]"
      }
     },
     "91fafe489226430dab0a8cf8b6378f3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "94daae398c544b3980fcd6c4bdbf398e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a2c1c079ed84451c9ac55ae8c9cc17ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a43d49204047467898a0031668f20c79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a48e82c6cabf4f8aa63d89206905ce33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_418906a372ba4dab84c8db5ce9721a3e",
       "placeholder": "​",
       "style": "IPY_MODEL_0edf1b5e3a8145c29c027831d681f296",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.07M/? [00:00&lt;00:00, 14.3MB/s]"
      }
     },
     "a51d22f5a7834963ab793872f7f1a348": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a9aabd79ca6a4b949186ab04db0d83ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b29fedd489cd4686a1bb4216208b2f45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8125518bac594022a06297c8d7fdf93b",
       "placeholder": "​",
       "style": "IPY_MODEL_a51d22f5a7834963ab793872f7f1a348",
       "tabbable": null,
       "tooltip": null,
       "value": "vocabulary.json: "
      }
     },
     "b5351c0896b245d2b80211849535a172": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "be877d400cb14454b30ea0f3cdb90e56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a2c1c079ed84451c9ac55ae8c9cc17ba",
       "placeholder": "​",
       "style": "IPY_MODEL_5af53e6aff03496290f52c3bfa429365",
       "tabbable": null,
       "tooltip": null,
       "value": " 340/340 [00:00&lt;00:00, 13.1kB/s]"
      }
     },
     "c83ebd67ceb0412baf7a3ee9c54c79f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb006df9508e4bfd98034a61435aea68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ce6694af12b541d49cd5029a099530f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d3c49b8ca46e4b8183e88b5ca34b82af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2245a61acaed4e05a838b01dd70759cb",
        "IPY_MODEL_3bd56f0eb80d4652bc7d0948544df8c1",
        "IPY_MODEL_7caecfbcd79648079dab3f15d0cc9e0b"
       ],
       "layout": "IPY_MODEL_7da76598d8ec45908cc57a310f3b42c2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d91341c1051c41f6ae245bc0f1861907": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e39956d6325c4037b3953a3ef5733dc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e6464368dced437ebb28bd1864b0658b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e676886ea6794af387f3eece2baa7768": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebec22acec174f859df0cf4a43212148": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "f18c730737a9476eadb90fcadb2dd66a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "f8e18f6333ce407e883945a996cc7342": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_620d22bab5ad468d9436a390bf46bffe",
       "max": 3087284237.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d91341c1051c41f6ae245bc0f1861907",
       "tabbable": null,
       "tooltip": null,
       "value": 3087284237.0
      }
     },
     "fa8f0dba35de432da55a108ebb6dea6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7a33c7a9ef014cbda56e003a479ed552",
       "placeholder": "​",
       "style": "IPY_MODEL_63cf946809584b6a9ffd46d0285144c2",
       "tabbable": null,
       "tooltip": null,
       "value": "model.bin: 100%"
      }
     },
     "fd78cc95ae9c41bb929f83f8409a9949": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe7b96962efd4ee281ff0ae9db983094": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
